<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: concurrency | Bits, Bytes, and Words]]></title>
  <link href="https://blog.jez.io/categories/concurrency/atom.xml" rel="self"/>
  <link href="https://blog.jez.io/"/>
  <updated>2019-05-21T21:09:32-04:00</updated>
  <id>https://blog.jez.io/</id>
  <author>
    <name><![CDATA[Jake Zimmerman]]></name>
    <email><![CDATA[jake@zimmerman.io]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Concurrent Programming in ML: A Race]]></title>
    <link href="https://blog.jez.io/cpml-race/"/>
    <updated>2018-07-18T00:23:23-04:00</updated>
    <id>https://blog.jez.io/cpml-race</id>
    <content type="html"><![CDATA[<p>Lately I&rsquo;ve been super interested in language models for concurrency,
after hearing a fascinating talk from Adam Solove on <a href="https://medium.com/@asolove/synchronizable-abstractions-for-understandable-concurrency-64ae57cd61d1">synchronizable
abstractions for UI</a>.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> I&rsquo;ve been working my way through a
handful of books, including <a href="https://simonmar.github.io/pages/pcph.html">PCPH</a>, the Concurrency section of <a href="http://www.cs.cmu.edu/~rwh/pfpl.html">PFPL</a>,
and most recently <a href="http://www.cambridge.org/gb/academic/subjects/computer-science/distributed-networked-and-mobile-computing/concurrent-programming-ml?format=AR">Concurrent Programming in ML</a>, by John Reppy.</p>

<p>In particular, I think I&rsquo;ve found a race condition in one of the code
listings of Concurrent Programming in ML. After introducing the listing
itself, we&rsquo;ll walk through a trace that shows the errant behavior, then
propose a small change that prevents it from happening.</p>

<h2>Setup: Snippets from the Book</h2>

<p>Before we begin, here&rsquo;s the listing in full. It&rsquo;s a sample
implementation of a 1-element concurrent buffer, using condition
variables. It supports creation, insertion, and removal.</p>

<pre><code class="sml Concurrent Programming in ML, Listing 2.3">datatype 'a buffer = BUF of {
  data      : 'a option ref,
  mu        : mutex,
  dataAvail : condition,
  dataEmpty : condition
}

fun buffer () =
  let val mu = mutex() in
    BUF {
      data      = ref NONE,
      mu        = mu,
      dataAvail = condition mu,
      dataEmpty = condition mu
    }
  end

fun insert (BUF {data, mu, dataAvail, dataEmpty}, v) =
  let
    fun waitLp NONE = (data := SOME v; signal dataAvail)
      | waitLp (SOME v) = (wait dataEmpty; waitLp (!data))
  in
    withLock mu waitLp (!data)
  end

fun remove (BUF {data, mu, dataAvail, dataEmpty}) =
  let
    fun waitLp NONE = (wait dataAvail; waitLp (!data))
      | waitLp (SOME v) = (data := NONE; signal dataEmpty)
  in
    withLock mu waitLp (!data)
  end
</code></pre>

<p>You might also want to reference this exerpt which explains the
semantics of the concurrency primitives at play in the snippet above:
locks and condition variables. Study the listing above and exerpt below
for a moment. See if you can spot a race, or are convinced the code is
correct.</p>

<blockquote><p>The semantics of the expression</p>

<p><code>withLock mu f x</code></p>

<p>are that first the lock mu is acquired, then the function f is applied
to x, and then the function&rsquo;s result is returned after releasing the
lock.</p>

<p>The basic operations on condition variables are</p>

<p><code>val wait : condition -&gt; unit</code></p>

<p>which causes a process to block on the condition variable, and</p>

<p><code>val signal : condition -&gt; unit</code></p>

<p>which wakes up one waiting process. A condition variable is associated
with a specific mutex lock, which must be held when performing a wait
operation on the variable. The semantics of the wait operation are
that the mutex lock is released, and then the process is blocked; when
the condition is signaled, the next process in the condition&rsquo;s waiting
queue is unblocked and it reacquires the mutex lock and proceeds. A
signal operation on a condition variable that has an empty waiting
queue has no effect; in this sense condition variables are memoryless.</p>

<p>&mdash; <em>Concurrent Programming in ML</em>, section 2.4.2</p></blockquote>

<h2>A trace to expose the problem</h2>

<p>The problem I see has to do with SML&rsquo;s eager evaluation: before calling
a function <code>f e</code>, we evaluate <code>e</code> to a value <code>v</code>. Then substitution
kicks in and we substitute <code>v</code> into the body of <code>f</code>. For us,
that means that in the definition of <code>insert</code>:</p>

<pre><code class="sml">fun insert (* ··· *) =
  (* ··· *)
    withLock mu waitLp (!data)
  (* ··· *)
</code></pre>

<p>we evaluate <code>!data</code> to a value before we run the body of <code>withLock</code> to
acquire the lock. When inserting into an empty queue, <code>!data</code> evaluates
to <code>NONE</code>. And since this happens outside the <code>withLock</code> if two calls to
insert attempt to acquire the lock at the same time, they&rsquo;ll both think
the queue is empty when they wake up! When this happens, the one to wake
up second will unknowingly overwrite what the first one inserted.</p>

<p>Here&rsquo;s a sample trace of a program allocating a buffer and then
doing two concurrent insertions:</p>

<pre><code class="sml Sample trace, showing that first insert gets dropped">(* '=&gt;' marks steps where two threads evolve concurrently  *)
(* '-&gt;' marks steps where just one thread evalautes        *)

-&gt; val buf = buffer ()

(* Fork two threads; both have access to 'buf'.            *)

   (* thread 1 *)                       (* thread 2 *)
=&gt; insert buf 1                         insert buf 2
=&gt; withLock mu waitLp (!data)           withLock mu waitLp (!data)
=&gt; withLock mu waitLp NONE              withLock mu waitLp NONE

   (* thread 1 acquires lock *)
-&gt; waitLp NONE
-&gt; (data := SOME v; signal dataAvail)
-&gt; (data := SOME 1; signal dataAvail)
   (* {data = ref (SOME 1), ...} *)
-&gt; ((); signal dataAvail)
-&gt; signal dataAvail
-&gt; ()
   (* thread 1 releases lock *)

                                        (* thread 2 acquires lock *)
                                        (* NONE is now stale! *)
-&gt;                                      waitLp NONE
                                        (* selects wrong case in function *)
-&gt;                                      (data := SOME v; signal dataAvail)
-&gt;                                      (data := SOME 2; signal dataAvail)
                                        (* ==&gt; data = ref (SOME 2) *)
-&gt;                                      ((); signal dataAvail)
-&gt;                                      signal dataAvail
-&gt;                                      ()
</code></pre>

<p>Notice how the stale read allowed two consecutive inserts. What we
wanted was for the second insert to wake up, see that the buffer is
full, then wait for the <code>dataEmpty</code> condition variable to wake it up.
So having the <code>!data</code> outside the lock is not good.</p>

<h2>Fixing the stale read</h2>

<p>The solution to this is to delay evaluating <code>!data</code> until the body of the
<code>waitLp</code> function, which only executes when we have the lock. This
ensures that we don&rsquo;t read a stale value for the content of the buffer.</p>

<pre><code class="sml Listing 2.3, updated to avoid race">datatype 'a buffer = (* ··· *)
fun buffer () = (* ··· *)

fun insert (BUF {data, mu, dataAvail, dataEmpty}, v) =
  let
    (* !data is now within waitLp, so it's never stale. *)
    fun waitLp () =
      case !data
        of NONE =&gt; (data := SOME v; signal dataAvail)
         | SOME v =&gt; (wait dataEmpty; waitLp ())
  in
    withLock mu waitLp ()
  end

fun remove (BUF {data, mu, dataAvail, dataEmpty}) =
  let
    fun waitLp () =
      case !data
        of NONE =&gt; (wait dataAvail; waitLp ())
         | SOME v =&gt; (data := NONE; signal dataEmpty)
  in
    withLock mu waitLp ()
  end
</code></pre>

<p>Pretty small bug, and it doesn&rsquo;t detract from the main point of the
listing, which is to show how to use condition variables in a sort of
&ldquo;mutually recursive&rdquo; style where <code>dataEmpty</code> wakes up <code>insert</code> which
signals on <code>dataAvail</code> which wakes up <code>remove</code>.</p>

<p>This also underscores how difficult it really is to ensure correctness
in the presence of concurrency! That&rsquo;s exactly why I&rsquo;ve been reading
about all these language models for concurrency, to better understand
how we can leverage our programming language to ensure our programs are
correct by construction.</p>

<!-- vim:tw=72
-->

<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Unfortunately, the talk isn&rsquo;t online (Adam presented it at work), so the blog post linked above is the next best thing!<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
</feed>

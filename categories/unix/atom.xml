<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: unix | Bits, Bytes, and Words]]></title>
  <link href="https://blog.jez.io/categories/unix/atom.xml" rel="self"/>
  <link href="https://blog.jez.io/"/>
  <updated>2019-12-16T18:10:55-05:00</updated>
  <id>https://blog.jez.io/</id>
  <author>
    <name><![CDATA[Jake Zimmerman]]></name>
    <email><![CDATA[jake@zimmerman.io]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Surgery on Code from the Command Line]]></title>
    <link href="https://blog.jez.io/surgery-on-code/"/>
    <updated>2019-07-30T09:32:48-07:00</updated>
    <id>https://blog.jez.io/surgery-on-code</id>
    <content type="html"><![CDATA[<p>I&rsquo;m frequently faced wth problems like &ldquo;find and replace this pattern,
but only on specific lines,&rdquo; especially lines that have type errors on
them. I&rsquo;ve built three new CLI tools that fit the need to operate on a
specific set of lines in a codebase. In this post I&rsquo;ll walk through a
couple examples to show them in action.</p>

<!-- more -->


<p>For the impatient, the tools that I&rsquo;ve built are:</p>

<ul>
<li><p><a href="https://github.com/jez/multi-grep"><code>multi-grep</code></a></p>

<p>Like <code>grep</code>, but search for a pattern only at the specified
locations, printing the locations where a match was found.</p></li>
<li><p><a href="https://github.com/jez/multi-sub"><code>multi-sub</code></a></p>

<p>Substitute a pattern with a replacement at the specified locations,
editing the file in place.</p></li>
<li><p><a href="https://github.com/jez/diff-locs"><code>diff-locs</code></a></p>

<p>Convert a unified diff (like the output of <code>git diff</code>) into a list
of locations affected by that diff.</p></li>
</ul>


<p>With the quick intros out of the way, let&rsquo;s dive into some examples.</p>

<h2><code>multi-grep</code></h2>

<p>Consider the file <code>locs.txt</code> below which is a list of <code>filename:line</code>
pairs:</p>

<pre><code class="plain locs.txt">file_a.txt:13
file_a.txt:22
file_a.txt:79
file_b.txt:10
file_b.txt:11
</code></pre>

<p>(I call such <code>filename:line</code> pairs &ldquo;locations&rdquo; or &ldquo;locs.&rdquo;)</p>

<p>Also consider that our project is huge, and has many more files
than just <code>file_a.txt</code> and <code>file_b.txt</code>. To filter the <code>locs.txt</code> list
to only the lines that contain the pattern &ldquo;hello&rdquo;, we can use
<code>multi-grep</code>:</p>

<pre><code class="bash">❯ multi-grep 'hello' locs.txt
file_a.txt:13
file_b.txt:10
</code></pre>

<p>The output means that only line 13 in <code>file_a.txt</code> and line 10 in
<code>file_b.txt</code> contain <code>hello</code>, given our initial set of 5 locs. The
search completely ignored all other files in the project because they
weren&rsquo;t mentioned in <code>locs.txt</code>. Searching with <code>multi-grep</code> scales with
the size of the input list, not with the size of the codebase being
searched.</p>

<p>This was a contrived example, but let&rsquo;s keep plowing forward with the
basics so we can apply them to a real example.</p>

<h2><code>multi-sub</code></h2>

<p>If <code>multi-grep</code> is like <code>grep</code>, <code>multi-sub</code> is like <code>sed</code> but with only
the substitute command (<code>s/find/replace/</code>). Taking our previous example,
<code>multi-sub</code> finds and replaces a pattern on specific input lines:</p>

<pre><code class="bash">❯ multi-sub 'hello' 'goodbye' locs.txt
# ... file_a.txt:13 edited: s/hello/goodbye/ ...
# ... file_b.txt:10 edited: s/hello/goodbye/ ...
</code></pre>

<p>In our previous example, only locations <code>file_a.txt:13</code> and
<code>file_b.txt:10</code> matched the pattern <code>hello</code>. So after running this
<code>multi-sub</code> command, those two files will be updated in place. On both
lines, <code>hello</code> will be replaced with <code>goodbye</code>.</p>

<h2>A larger example</h2>

<p>With the basics out of the way, let&rsquo;s tackle a real-world problem. I
work with the output of <a href="https://sorbet.org">Sorbet</a> a lot, so I&rsquo;ve used it for this next
example (Sorbet is a type checker for Ruby). When Sorbet detects type
errors in a program, it generates output like this:</p>

<pre><code>test/payment_methods/update.rb:648: Method `[]` does not exist on `NilClass` component of `T.nilable(T::Hash[T.untyped, T.untyped])` http://go/e/7003
     648 |   assert_equal(nil, previous['billing_details']['address']['line1'])
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^

test/payment_methods/update.rb:649: Method `[]` does not exist on `NilClass` component of `T.nilable(T::Hash[T.untyped, T.untyped])` http://go/e/7003
     649 |   assert_equal(nil, previous['card']['checks']['address_line1_check'])
                               ^^^^^^^^^^^^^^^^

test/payment_methods/webhooks.rb:610: Method `[]` does not exist on `NilClass` component of `T.nilable(T::Hash[T.untyped, T.untyped])` http://go/e/7003
     610 |   assert_equal(2, notification['card']['exp_month'])
                             ^^^^^^^^^^^^^^^^^^^^

... many more errors ...

Errors: 253
</code></pre>

<p>The error messages look a lot better with colors! If you don&rsquo;t believe
me, you can <a href="https://sorbet.run">try Sorbet in the browser</a> and see for
yourself.</p>

<p>The example above is inspired by real output that we saw at Stripe while
iterating on Sorbet. In this specific case, one of my coworkers had
improved Sorbet to track more information statically, which uncovered a
bunch of new type errors.</p>

<p>On the Sorbet team, we have a policy that before landing changes like
this, we modify Stripe&rsquo;s monorepo to preemptively silence the new
errors. Jordan Brown has a great article on the <a href="https://medium.com/flow-type/upgrading-flow-codebases-40ef8dd3ccd8">Flow blog</a> justifying
this technique, so I&rsquo;ll skip the why and focus only on how to carry out
codemods like this.</p>

<p>As seen above, Sorbet error output always looks like
<code>filename.rb:line:Error message</code>. With a little massaging, this will
feed directly into <code>multi-sub</code>. Also notice that on the lines with
errors, the file contents always looked something like this:</p>

<pre><code class="ruby">foo['bar']
</code></pre>

<p>To tell Sorbet to silence the errors on these lines, we&rsquo;ll need to wrap
the variable in a call to <code>T.unsafe(...)</code>:</p>

<pre><code class="ruby">T.unsafe(foo)['bar']
</code></pre>

<p>This instructs to Sorbet to <a href="https://sorbet.org/docs/troubleshooting#escape-hatches">forget all static type
information</a> about the variable, thus silencing the error.
The key is to only perform this edit on lines with errors&mdash;
we&rsquo;d hate to needlessly throw away type information by changing
unrelated lines! For things like this, <code>grep</code> and <code>sed</code> are often too
coarse-grained, because accessing a hash like this in Ruby is abundantly
common.</p>

<p>With <code>multi-sub</code>, we can write a really simple regex targetting these
hash lookups, but scope the regex to only lines in the error output:</p>

<pre><code class="bash"># (1) Type check the project
❯ srb tc 2&gt;&amp;1 | \
  # (2) Filter the error output to only have the top-level error lines
  sed -e '/^ /d; /^$/d; /^Errors:/d' | \
  # (3) Chop off the error message, keeping only the filename:line
  cut -d : -f 1-2 | \
  # (4) Use multi-sub to replace things like foo[ with T.unsafe(foo)[
  multi-sub '\([a-zA-Z0-9_]+\)\[' 'T.unsafe(\1)['
</code></pre>

<p>Take a look through the four steps in the bash oneliner above:</p>

<ol>
<li>Type check the project, then</li>
<li>filter out every line that doesn&rsquo;t have a location, then</li>
<li>chop of the error messages, and finally</li>
<li>use <code>multi-sub</code> to perform the substitution.</li>
</ol>


<p>The net result is to update the files in place, performing the
substitution only on the lines with errors. Altogether once more, but on
one line, making use of a shell alias that I have to abbreviate the
inner two steps:</p>

<pre><code class="bash">❯ srb tc 2&gt;&amp;1 | onlylocs | multi-sub '\([a-zA-Z0-9_]+\)\[' 'T.unsafe(\1)['
</code></pre>

<p>So with a super short bash oneliner, we&rsquo;ve done a mass codemod that
fixes hundreds of errors at once, without having to silence more than
necessary.</p>

<p>If <code>grep</code> and <code>sed</code> are like chainsaws, I like to think of <code>multi-grep</code>
and <code>multi-sub</code> like scalpels&mdash;ideal for performing surgery on a
codebase. Regular expressions are often super imprecise tools for
codemods. But by scoping down the regex to run only on specific lines,
it doesn&rsquo;t matter. The added precision from explicit locations makes up
for how blunt regular expressions are.</p>

<h2><code>diff-locs</code></h2>

<p>I&rsquo;ve built one more command in the same spirit as <code>multi-grep</code> and
<code>multi-sub</code>, except that instead of consuming locations, it emits them.
Specifically, given a diff it outputs one <code>filename:line</code> pair for every
line that was affected by the diff.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> It&rsquo;s ideal for consuming the
output of <code>git show</code> or <code>git diff</code>:</p>

<pre><code>❯ git show HEAD | diff-locs
test/payment_methods/update.rb:648
test/payment_methods/update.rb:649
test/payment_methods/webhooks.rb:610
</code></pre>

<p>I frequently use <code>diff-locs</code> to tweak codemods that I&rsquo;ve already
committed. For example, we could go back and add a TODO comment above
each new <code>T.unsafe</code> call:</p>

<pre><code class="bash"># (1) Generate a diff from git
❯ git show HEAD | \
  # (2) Convert the diff to a list of locations
  diff-locs | \
  # (3) Use multi-sub to insert a comment before each line
  multi-sub '^\( *\)' $'\\1# TODO: Unsilence this error\n\\1'
</code></pre>

<p>Recapping the pipeline above:</p>

<ol>
<li>Use <code>git show</code> to generate a diff, then</li>
<li>convert the diff to a list of locations with <code>diff-locs</code>, and finally</li>
<li>insert a comment before each location with <code>multi-sub</code>.</li>
</ol>


<p><code>diff-locs</code> is particularly handy because after the first codemod, there
won&rsquo;t be type errors anymore! So to get a list of locations to perform
the edit on, we&rsquo;d have had to check out the commit before fixing the
errors, save the list of errors to a file, go back, and finally do the
edit we wanted to in the first place.</p>

<p>Instead, we can take advantage of the fact that all that information is
already stored in git history, skipping a bunch of steps. (And asking
git to show a diff is way faster than asking Sorbet to re-typecheck a
whole project 😅)</p>

<h2>Aside: The implementations</h2>

<p>One thing I&rsquo;d like to point out is that I took some care to make sure
these commands weren&rsquo;t eggregiously slow. I prototyped these commands
with some hacky scripts, but after doing some rather large codemods I
got annoyed with them taking minutes to finish.</p>

<p>Some things that make these new commands fast:</p>

<ul>
<li><code>multi-grep</code> and <code>multi-sed</code> re-use an already opened file to avoid
reading extra information.</li>
<li><code>multi-grep</code> is written in Standard ML, <code>multi-sub</code> is written in
OCaml, and <code>diff-locs</code> is written in Haskell&mdash;all languages which
have great optimizing compilers. This means much better performance
than a scripting language.</li>
</ul>


<p>If you&rsquo;re curious, you can read through their implementations on GitHub:</p>

<ul>
<li><a href="https://github.com/jez/multi-grep"><code>multi-grep</code></a></li>
<li><a href="https://github.com/jez/multi-sub"><code>multi-sub</code></a></li>
<li><a href="https://github.com/jez/diff-locs"><code>diff-locs</code></a></li>
</ul>


<p>As always if you have questions or notice issues please don&rsquo;t hesitate
to reach out!</p>

<!-- vim:tw=72
-->

<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>It defaults to only lines affected after the diff applies, but there&rsquo;s an option to make it show both added and removed lines.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Improving CLIs with isatty]]></title>
    <link href="https://blog.jez.io/cli-tty/"/>
    <updated>2019-06-11T12:17:59-07:00</updated>
    <id>https://blog.jez.io/cli-tty</id>
    <content type="html"><![CDATA[<p>One thing I like to do to improve the command-line programs I maintain
is to make them aware of whether they&rsquo;re being run interactively. In
this post I&rsquo;ll show off an easy trick to make programs running
interactively more usable.</p>

<!-- more -->


<p>This always used to trip me up when I was first learning to use the
terminal:</p>

<pre><code class="bash">❯ grep 'def foo'
</code></pre>

<p>I&rsquo;d drop this into the command-line and what happens? It hangs&hellip; Is it
because it&rsquo;s taking a long time to search? Nope—I&rsquo;ve forgetten to tell
<code>grep</code> what files to search in!</p>

<p>When <code>grep</code> is given only a pattern to search for and no files to search
in, it assumes we want to search for that pattern on stdin. This is
great for shell scripts and one-liners at the command-line, but it&rsquo;s
<strong>super</strong> annoying when we&rsquo;re just grepping interactively.</p>

<p>The thing is, it&rsquo;s super easy to detect when the user might have made
this mistake: if we&rsquo;re defaulting to reading from stdin <strong>and</strong> the file
corresponding to stdin represents a terminal (more specifically, a
<a href="https://unix.stackexchange.com/questions/4126/">tty</a>). And once we&rsquo;ve detected it, we can print a helpful message.</p>

<p>Here&rsquo;s how I did it when writing <a href="https://github.com/jez/diff-locs"><code>diff-locs</code></a>, one of the command-line
programs I&rsquo;ve been working on lately:</p>

<pre><code class="haskell Check if stdin is a tty in Haskell">fileIn &lt;- case inputStyle of
  InputFromFile filename -&gt; IO.openFile filename IO.ReadMode
  InputFromStdin         -&gt; do
    isTTY &lt;- hIsTerminalDevice IO.stdin
    when isTTY $ do
      errPutStrLn "Warning: reading from stdin, which is a tty."
    return IO.stdin
</code></pre>

<p>If we&rsquo;ve been given a file explicitly, just open it. Otherwise, fall
back to reading from stdin. But first, check if <code>IO.stdin</code> is a terminal
device and when it <strong>is</strong>, print a warning.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> The complete file
containing the snippet above is <a href="https://github.com/jez/diff-locs/blob/743bff5cb1abb6e405b0369b195614aea6ec018d/app/Main.hs#L17-L24">on GitHub</a>.</p>

<p>I&rsquo;ve implemented <code>diff-locs</code> as a standard Unix filter—it takes input on
stdin and emits output on stdout. Normal usage looks something like
this, where we pipe <code>git diff</code> into <code>diff-locs</code>:</p>

<pre><code class="bash">❯ git diff | diff-locs
</code></pre>

<p>But if someone is just playing around at the terminal (maybe, trying to
get the help output to show up), they might run <code>diff-locs</code> without
args, and then be greeted with this message:</p>

<pre><code>❯ diff-locs
Warning: reading from stdin, which is a tty.
█
</code></pre>

<p>This is much better than just sitting there appearing to hang!</p>

<h2><code>isatty</code> in other languages</h2>

<p>The trick above works in pretty much every language that supports Unix
programming. Under the hood, the Haskell snippet above is powered by the
<code>isatty</code> function in the C standard library (<code>man 3 isatty</code>), which most
other languages wrap in some way. For example, three other languages I&rsquo;ve
done this in recently:</p>

<pre><code class="ruby Ruby">if STDIN.isatty?
  STDERR.puts 'Warning: reading from stdin, which is a tty.'
end
</code></pre>

<pre><code class="bash Bash">if [ -t 0 ]; then
  echo 'Warning: reading from stdin, which is a tty.' &gt;&amp;2
end
</code></pre>

<pre><code class="ocaml OCaml">if Unix.isatty Unix.stdin
then prerr_endline "Warning: reading from stdin, which is a tty."
else ()
</code></pre>

<p>And again, a quick search for <code>isatty &lt;language&gt;</code> should suffice for any
language that supports Unix programming. It&rsquo;s little things like this
that add up and make certain command-line utilities delightful to use.</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>We don&rsquo;t really need to check whether the file we&rsquo;re opening is a tty. If the user managed to pass in the <em>name</em> of a tty file, they probably know what they&rsquo;re doing.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Google Chrome: A Memory Hog]]></title>
    <link href="https://blog.jez.io/2014/12/29/google-chrome-a-memory-hog/"/>
    <updated>2014-12-29T17:00:00-06:00</updated>
    <id>https://blog.jez.io/2014/12/29/google-chrome-a-memory-hog</id>
    <content type="html"><![CDATA[<p>Whenever someone complains about a slow computer, the first thing I check is
how many Chrome tabs they have open. Chrome hogs memory like no other. For
users, this means Chrome is snappy and responsive, but oftentimes it comes at
the expense of crowding out other programs. To get an idea of how much memory
Chrome is really using, I wrote a quick bash oneliner.</p>

<!-- more -->


<h2>Why does Chrome Hog Memory?</h2>

<p><a href="http://mobile.extremetech.com/latest/221392-iframe-irony-adblock-plus-is-probably-the-reason-firefox-and-chrome-are-such-memory-hogs">An article posted to Hacker News</a> recently brought some light to
the question of why Chrome and Firefox suck up so much memory: Adblock Plus. The
general idea is that the excessive use of iframes in most websites today ramps
up the amount of processing that Adblock Plus has to do, driving memory usage
through the roof. For more specifics, check out the rest of of the article.</p>

<h2>The Oneliner</h2>

<p>For the impatient, here&rsquo;s the code. It uses standard Unix tools:</p>

<pre><code class="bash Chrome Memory Usage">$ ps -ev | grep -i chrome | awk '{print $12}' | awk '{for(i=1;i&lt;=NF;i++)s+=$i}END{print s}'
</code></pre>

<p>Pretty isn&rsquo;t it? If you want to save this as an alias for handy use, add this
line to your ~/.bashrc (or appropriate configuration file):</p>

<pre><code class="bash Add as an alias">alias chromemem="ps -ev | grep -i chrome | awk '{print \$12}' | awk '{for(i=1;i&lt;=NF;i++)s+=\$i}END{print s}'"
</code></pre>

<p>It outputs a percentage. Here&rsquo;s the alias in action:</p>

<pre><code class="bash Usage">$ chromemem
60
</code></pre>

<h2>Explanation</h2>

<p>There&rsquo;s a lot of good stuff going on here, so let&rsquo;s take it step-by-step.</p>

<p>First, we&rsquo;ll need a program that tells us memory usage. I&rsquo;m sure there are many,
but I&rsquo;m familiar with <code>ps</code>. After checking out the man page for a few options, I
came up with <code>ps -ev</code>, to show all information about all processes. Maybe
wasteful, but it works.</p>

<pre><code class="bash ps -ev">$ ps -ev
  PID STAT      TIME  SL  RE PAGEIN      VSZ    RSS   LIM     TSIZ  %CPU %MEM COMMAND
 3473 S      0:54.92   0   0      0  3579092 301244     -        0   6.7  7.2 /Applications/Google C
  365 S      3:03.17   0   0      0  3920732 206808     -        0   0.3  4.9 /Applications/Google C
  983 S      1:29.23   0   0      0  3560272 193860     -        0   0.1  4.6 /Applications/Google C
  395 S      0:13.11   0   0      0  2824936 141644     -        0   0.0  3.4 /Applications/Google C
  422 S      0:27.22   0   0      0  3345796 130796     -        0   0.0  3.1 /Applications/Google C
  ...
</code></pre>

<p>Notice that there&rsquo;s a convenient column describing memory usage as a percentage
of total available memory, as well as what command is being run in that
process. Let&rsquo;s make sure that we&rsquo;re looking at only the processes running
some sort of Chrome service before totaling up the memory. We can find these
lines with <code>ps -ev | grep -i chrome</code> (the -i means case-insensitive). Due to the
way I clipped the previous sample output, nothing changes in the first five
lines, but rest assured: we&rsquo;re only looking at Chrome processes now.</p>

<p>Now it&rsquo;s time to get rid of all the other nonsense that we included with <code>ps
-ev</code>. Luckily, there&rsquo;s a handy tool called <code>awk</code> that makes parsing text by
column easy. If we want to print the 12th column (which just so happens to
contain the memory consumption!) we can do <code>awk '{print $12}'</code>:</p>

<pre><code class="bash ps -ev | grep -i chrome | awk '{print $12}'">$ ps -ev | grep -i chrome | awk '{print $12}'
7.2
5.1
4.6
3.4
3.2
...
</code></pre>

<p>Finally, I found myself needing a way to add up a column of numbers. A quick
Google search led me to <a href="http://stackoverflow.com/questions/2572495/read-from-file-and-add-numbers">this StackOverflow question</a>, and I picked the
<code>awk</code> solution because I knew I could just pipe the input to awk (as opposed to
having to do weird hacks to get it to work with a bash for loop):</p>

<pre><code class="bash Final Solution">$ ps -emv | grep -i chrome | awk '{print $12}' | awk '{for(i=1;i&lt;=NF;i++)s+=$i}END{print s}'
60.4
</code></pre>

<p>Of course, you could change the last <code>awk</code> command to print out something
fancier like</p>

<pre><code class="bash Final Solution">$ ps -emv | grep -i chrome | awk '{print $12}' | awk '{for(i=1;i&lt;=NF;i++)s+=$i}END{print "Chrome is using "s"% of total memory."}'
Chrome is using 60.4% of total memory.
</code></pre>

<p>There you have it! Bash oneliners save the day yet again.</p>

<h2>Update</h2>

<p>After writing this article, I stopped using Ad Block Plus, and I noticed a
significant drop in Chrome&rsquo;s memory usage. Obviously, though, that came at the
cost of not blocking ads! Also, from time to time I would encounter a site that
seemed sluggish, presumably because of all the ads attempting to be loaded. My
simple solution to this was just to disable JavaScript on that page (I use an
extension called Quick JavaScript Switcher), but this wasn&rsquo;t an automated
solution.</p>

<p>Then I discovered <a href="https://github.com/gorhill/uBlock">μBlock</a>, an &ldquo;efficient blocker for Chromium and
Firefox.&rdquo; The fancy graphs on it&rsquo;s homepage convinced me to give it a shot, and
from what I can tell so far it&rsquo;s responsive and effective.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Offline LaTeX Development]]></title>
    <link href="https://blog.jez.io/2014/10/06/offline-latex-development/"/>
    <updated>2014-10-06T18:00:00-04:00</updated>
    <id>https://blog.jez.io/2014/10/06/offline-latex-development</id>
    <content type="html"><![CDATA[<p>While online clients like ShareLaTeX or writeLaTeX are popular for getting
started with LaTeX quickly, developing LaTeX locally with Vim and the command
line is my preferred LaTeX workflow. In this post, I&rsquo;ll describe the changes
I&rsquo;ve made that make working with LaTeX on the command line a seamless
experience.</p>

<!-- more -->


<h2>Install LaTeX</h2>

<p>Obviously, to work with LaTeX locally, you&rsquo;ll need LaTeX installed. To check if
you already have it installed, you can run <code>which pdflatex</code>. If it&rsquo;s installed,
this command will tell you the path to program. Otherwise, it won&rsquo;t print
anything.</p>

<h3>On Linux</h3>

<p>Installing LaTeX on Linux isn&rsquo;t too bad. Usually it&rsquo;s included in your
distribution&rsquo;s package manager. I&rsquo;ll be focusing on OS X for the majority of
this post though, so Google around if you end up having trouble.</p>

<h3>On OS X</h3>

<p>To install LaTeX on a Mac, we&rsquo;ll be installing MacTeX, which includes the
command line LaTeX utilities as well as a couple graphical clients for LaTeX
development. You can try compiling from source, but as Homebrew points out when
you try to <code>brew install latex</code>:</p>

<pre><code class="plain">$ brew install latex
Error: No available formula for latex
Installing TeX from source is weird and gross, requires a lot of patches,
and only builds 32-bit (and thus can't use Homebrew deps on Snow Leopard.)

We recommend using a MacTeX distribution: http://www.tug.org/mactex/
</code></pre>

<p>With that in mind, head on over to
<a href="http://www.tug.org/mactex/">http://www.tug.org/mactex/</a> and download the file
<code>MacTeX.pkg</code>. Once this has downloaded and you&rsquo;ve clicked through the
installer, you should be ready to go with LaTeX. Verify this by running <code>which
pdflatex</code> again.</p>

<h2>Use Vim</h2>

<p>The biggest productivity improvement you gain from developing LaTeX locally is
that you get to use Vim. Make sure you have a nice colorscheme for both your
terminal and for Vim. <strong>I can&rsquo;t stress enough how important it is to make your
terminal look nice</strong>: you want to enjoy your terminal experience, and this is
one of the easiest ways to do so.</p>

<h2>Use Make</h2>

<p>Compiling LaTeX is pretty straightforward. To generate a PDF, all you have to do
is run the command</p>

<pre><code class="bash">$ pdflatex &lt;myfile&gt;.tex
</code></pre>

<p>and you&rsquo;ll get a file called <code>&lt;myfile&gt;.pdf</code> in the current directory, plus some
intermediate files. We can go one step further and put a bunch of useful build
targets into a Makefile and use it to build our PDF:</p>

<pre><code class="make LaTeX Makefile https://gist.github.com/jez/b248a409d19c9f1c94cd"># NOTE: Change "written" to the name of your TeX file with no extension
TARGET=written

all: $(TARGET).pdf

## Generalized rule: how to build a .pdf from each .tex
LATEXPDFS=$(patsubst %.tex,%.pdf,$(wildcard *.tex))
$(LATEXPDFS): %.pdf: %.tex
  pdflatex -interaction nonstopmode $(patsubst %.pdf,%.tex,$@)

clean:
  rm *.aux *.log || true

veryclean: clean
  rm $(TARGET).pdf

view: $(TARGET).pdf
  if [ "Darwin" = "$(shell uname)" ]; then open $(TARGET).pdf ; else evince $(TARGET).pdf ; fi

submit: $(TARGET).pdf
  cp $(TARGET).pdf ../

print: $(TARGET).pdf
  lpr $(TARGET).pdf

.PHONY: all clean veryclean view print
</code></pre>

<p>If you save this to a file called <code>Makefile</code> in the same directory as your LaTeX
file, we can just run <code>make</code> instead of running <code>pdflatex &lt;myfile&gt;.tex</code>!</p>

<p>As you can see, there are a bunch of other handy targets here:</p>

<ul>
<li><code>make clean</code> will remove all intermediate files that are created.</li>
<li><code>make veryclean</code> will remove all intermediate files and the compiled PDF file.</li>
<li><code>make view</code> will compile the file and then open it up in a PDF viewer (if
you&rsquo;re on OS X, or on Linux and have <code>evince</code> installed).</li>
<li><code>make print</code> will send your document to the default printer with the default
options for that printer.</li>
<li><code>make submit</code> will copy your file into the parent directory. This is handy
when you&rsquo;re working in a subfolder on an assignment to isolate the
intermediate files, but your class has provided a handin script that needs the
PDF file to be in the parent directory.</li>
</ul>


<h2>Workflow Tips</h2>

<p>Right now, our workflow looks like this:</p>

<ul>
<li>Create TeX file</li>
<li>Edit in Vim</li>
<li>Switch to terminal</li>
<li>Run make view to compile and view</li>
</ul>


<p>We can actually optimize this workflow to one less step: we don&rsquo;t have to get
out of Vim to run make!</p>

<p>Vim has a command <code>:make</code> that will look for a Makefile in the current directory
and run it&rsquo;s <code>all</code> target. It also takes a target as an optional argument, so we
can do <code>:make view</code> to compile and view the document from within Vim!</p>

<p>Taking this one step further, we can add a command to shorten this. If we add</p>

<pre><code class="vim Save, Compile and View in Vim">command WV w | make view
</code></pre>

<p>to our <code>.vimrc</code>, we&rsquo;ll only have to type <code>:WV</code> to save, compile, and view our
PDF output.</p>

<h2>Wrap Up</h2>

<p>That&rsquo;s it! I like this experience for a bunch of reasons:</p>

<ul>
<li><strong>It&rsquo;s faster</strong>. Compiling LaTeX without having to wait for a web client to
load is really nice.</li>
<li><strong>It&rsquo;s more stable</strong>. You can still edit, compile, and view your work if you
don&rsquo;t have access to the Internet.</li>
<li><strong>It&rsquo;s faster</strong>. Using Vim to edit text is much more convenient than a
standard text editor.</li>
</ul>


<p>Do you have a LaTeX tip, a fancier Makefile, or a favorite vim plugin for LaTeX?
Share it in the comments!</p>

<h2><a href="/2015/01/10/offline-latex-development-part-2/">Part 2</a>!</h2>

<p>Actually that&rsquo;s not it, there&rsquo;s more! I wrote a <a href="/2015/01/10/offline-latex-development-part-2/">Part 2</a> to this post, which you
should definitely check out.</p>
]]></content>
  </entry>
  
</feed>

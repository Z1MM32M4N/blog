<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: bash | Bits, Bytes, and Words]]></title>
  <link href="https://blog.jez.io/categories/bash/atom.xml" rel="self"/>
  <link href="https://blog.jez.io/"/>
  <updated>2019-06-11T12:49:54-04:00</updated>
  <id>https://blog.jez.io/</id>
  <author>
    <name><![CDATA[Jake Zimmerman]]></name>
    <email><![CDATA[jake@zimmerman.io]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Improving CLIs with isatty]]></title>
    <link href="https://blog.jez.io/cli-tty/"/>
    <updated>2019-06-09T00:17:59-04:00</updated>
    <id>https://blog.jez.io/cli-tty</id>
    <content type="html"><![CDATA[<p>One thing I like to do to improve the command-line programs I maintain
is to make them aware of whether they&rsquo;re being run interactively. In
this post I&rsquo;ll show off an easy trick to make programs running
interactively more usable.</p>

<!-- more -->


<p>This always used to trip me up when I was first learning to use the
terminal:</p>

<pre><code class="bash">❯ grep 'def foo'
</code></pre>

<p>I&rsquo;d drop this into the command-line and what happens? It hangs&hellip; Is it
because it&rsquo;s taking a long time to search? Nope—I&rsquo;ve forgetten to tell
<code>grep</code> what files to search in!</p>

<p>When <code>grep</code> is given only a pattern to search for and no files to search
in, it assumes we want to search for that pattern on stdin. This is
great for shell scripts and one-liners at the command-line, but it&rsquo;s
<strong>super</strong> annoying when we&rsquo;re just grepping interactively.</p>

<p>The thing is, it&rsquo;s super easy to detect when the user might have made
this mistake: if we&rsquo;re defaulting to reading from stdin <strong>and</strong> the file
corresponding to stdin represents a terminal (more specifically, a
<a href="https://unix.stackexchange.com/questions/4126/">tty</a>). And once we&rsquo;ve detected it, we can print a helpful message.</p>

<p>Here&rsquo;s how I did it when writing <a href="https://github.com/jez/diff-locs"><code>diff-locs</code></a>, one of the command-line
programs I&rsquo;ve been working on lately:</p>

<pre><code class="haskell Check if stdin is a tty in Haskell">fileIn &lt;- case inputStyle of
  InputFromFile filename -&gt; IO.openFile filename IO.ReadMode
  InputFromStdin         -&gt; do
    isTTY &lt;- hIsTerminalDevice IO.stdin
    when isTTY $ do
      errPutStrLn "Warning: reading from stdin, which is a tty."
    return IO.stdin
</code></pre>

<p>If we&rsquo;ve been given a file explicitly, just open it. Otherwise, fall
back to reading from stdin. But first, check if <code>IO.stdin</code> is a terminal
device and when it <strong>is</strong>, print a warning.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> The complete file
containing the snippet above is <a href="https://github.com/jez/diff-locs/blob/743bff5cb1abb6e405b0369b195614aea6ec018d/app/Main.hs#L17-L24">on GitHub</a>.</p>

<p>I&rsquo;ve implemented <code>diff-locs</code> as a standard Unix filter—it takes input on
stdin and emits output on stdout. Normal usage looks something like
this, where we <code>git diff</code> into <code>diff-locs</code>:</p>

<pre><code class="bash">❯ git diff | diff-locs
</code></pre>

<p>But if someone is just playing around at the terminal (maybe, trying to
get the help output to show up), they might run <code>diff-locs</code> without
args, and then be greeted with this message:</p>

<pre><code>❯ diff-locs
Warning: reading from stdin, which is a tty.
█
</code></pre>

<p>This is much better than just sitting there appearing to hang!</p>

<h2><code>isatty</code> in other languages</h2>

<p>The trick above works in pretty much every language that supports Unix
programming. Under the hood, the Haskell snippet above is powered by the
<code>isatty</code> function in the C standard library <code>(man 3 isatty)</code>, which most
other languages wrap in some way. For example, two other languages I&rsquo;ve
done this in recently:</p>

<pre><code class="ruby Ruby">if STDIN.isatty?
  STDERR.puts 'Warning: reading from stdin, which is a tty.'
end
</code></pre>

<pre><code class="ocaml OCaml">if Unix.isatty Unix.stdin
then prerr_endline "Warning: reading from stdin, which is a tty."
else ()
</code></pre>

<p>And again, a quick search for <code>isatty &lt;language&gt;</code> should suffice for any
language that supports Unix programming. It&rsquo;s little things like this
that add up and make certain command-line utilities delightful to use.</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>We don&rsquo;t really need to check whether the file we&rsquo;re opening is a tty. If the user managed to pass in the <em>name</em> of a tty file, they probably know what they&rsquo;re doing.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Standard ML in Travis&nbsp;CI]]></title>
    <link href="https://blog.jez.io/sml-travis-ci/"/>
    <updated>2019-06-04T12:26:45-04:00</updated>
    <id>https://blog.jez.io/sml-travis-ci</id>
    <content type="html"><![CDATA[<p>For one of my recent projects (<a href="https://github.com/jez/multi-grep"><code>multi-grep</code></a>) I went through the work to
get Standard ML building in Travis CI. It turned out to be not too
hard—in fact, the hardest part is already done, and I&rsquo;m happy to share
how it works.</p>

<!-- more -->


<h2>Features</h2>

<p>The way I set up my builds, I can:</p>

<ul>
<li>build and test with both macOS and Linux</li>
<li>build and test with both SML/NJ and MLton</li>
<li>create executables, even with SML/NJ</li>
<li>publish the resulting builds to GitHub as releases</li>
</ul>


<p>Apart from some scripts to install things on each operating system,
under the hood it&rsquo;s powered by <a href="https://github.com/jez/symbol">Symbol</a>, which is a build tool for
Standard ML I wrote which factors out most of the project-agnostic
stuff.</p>

<h2>The core setup</h2>

<p>Rather than paste the code into a snippet here and wait for it to get
out of date, see my <a href="https://github.com/jez/multi-grep"><code>multi-grep</code></a> project on GitHub for all the
up-to-date files. In total, there are three files in that repo which set
the whole thing up:</p>

<ol>
<li><a href="https://github.com/jez/multi-grep/blob/b6a42719b1ffca389556655982e6c4b7fa19c9a1/.travis.yml">.travis.yml</a> (kicks off the build)</li>
<li><a href="https://github.com/jez/multi-grep/blob/b6a42719b1ffca389556655982e6c4b7fa19c9a1/Brewfile">Brewfile</a> (deps for macOS build)</li>
<li><a href="https://github.com/jez/multi-grep/blob/b6a42719b1ffca389556655982e6c4b7fa19c9a1/tests/travis-install.sh">tests/travis-install.sh</a> (deps for Linux build)</li>
</ol>


<p>If you haven&rsquo;t used Travis CI before, you&rsquo;ll probably also want to check
out the <a href="https://docs.travis-ci.com/">Travis CI docs</a> to get a feel for how to actually set things
up, and where these pieces fit in.</p>

<h2>Why write a whole build tool?</h2>

<p>I mentioned above that I&rsquo;d written a build tool for Standard ML, called
<a href="https://github.com/jez/symbol">Symbol</a>. Why? It started as a shell script + <code>Makefile</code> for
<a href="https://github.com/jez/multi-grep"><code>multi-grep</code></a> and then I realized that these scripts could be useful in
any Standard ML project.</p>

<p>SML/NJ and MLton are already great compilers with their own build tools.
It&rsquo;s useful to be able to build a project with both (SML/NJ for faster
builds and a REPL, and MLton for faster compiled executables). All
Symbol really does is put SML/NJ and MLton behind a unified, very
stripped down interface.</p>

<p>There&rsquo;s more information <a href="https://github.com/jez/symbol">in the README</a>, but some key points:</p>

<ul>
<li>Symbol makes it easy to build and install executables, even with
SML/NJ which traditionally uses heap images.</li>
<li>Symbol is built on <code>make</code>, so if <strong>no</strong> source files change, even
recompiling with MLton is instant.</li>
<li>Symbol also supports scaffolding new Standard ML projects, which is
nicer than starting from scratch.</li>
</ul>


<p>Again, there&rsquo;s way more information <a href="https://github.com/jez/symbol">in the README</a>, so
definitely check it out if you&rsquo;re thinking about setting up a new
Standard ML project. The usage looks something like this:</p>

<pre><code class="bash"># initialize a new project:
❯ symbol-new hello
❯ cd hello

# build with SML/NJ:
❯ ./symbol make
❯ .symbol-work/bin/hello
Hello, world!

# or, build with MLton:
❯ ./symbol make with=mlton
❯ .symbol-work/bin/hello
Hello, world!
</code></pre>

<h2>Why Standard ML in the first place?</h2>

<p>I&rsquo;ll probably get around to writing about <a href="https://github.com/jez/multi-grep"><code>multi-grep</code></a> (and related
tools like <a href="https://github.com/jez/diff-locs"><code>diff-locs</code></a> and <a href="https://github.com/jez/multi-sub"><code>multi-sub</code></a>) but at the end of the day:
SML is a really pleasant language to use in a lot of ways:</p>

<ul>
<li>Type inference in Standard ML is a breath of fresh air.</li>
<li>Data types let me wonder less about how things work.</li>
<li>Pattern matching makes for concise, clean, and correct code.</li>
</ul>


<p>Standard ML was my most commonly used programming language throughout
all of my university courses, so there&rsquo;s a definite soft spot in my
heart for it. There are features that I wish it had sometimes, but it&rsquo;s
the only language that I&rsquo;ve used that doesn&rsquo;t feel fundamentally broken
in some way.</p>

<!-- vim:tw=72
-->

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Code Review from the Command Line]]></title>
    <link href="https://blog.jez.io/cli-code-review/"/>
    <updated>2018-01-13T16:14:24-05:00</updated>
    <id>https://blog.jez.io/cli-code-review</id>
    <content type="html"><![CDATA[<p>I do the bulk of my code reviews from the command line, especially when
reviewing larger changes. I&rsquo;ve built up a number of tools and config
settings that help me dig into the nuances of the code I&rsquo;m reviewing, so
that I can understand it better than if I were just browsing online.</p>

<!-- more -->


<p>In particular, I&rsquo;ll walk through how I&hellip;</p>

<ul>
<li>check out the code in the first place,</li>
<li>get a feel for what changed,</li>
<li>visualize the relationships between the files that changed,</li>
<li>bring up the code diffs in Vim,</li>
<li>leverage the unique power of the editor and the terminal.</li>
</ul>


<p>But first, let&rsquo;s talk briefly about the point of code review in the
first place.</p>

<h2>Code review philosophy</h2>

<p>When I ask that other people review my code, it&rsquo;s an opportunity for me
to teach them about the change I&rsquo;ve just made. When I review someone
else&rsquo;s code, it&rsquo;s to learn something from them. Some other benefits of
code review include:</p>

<ul>
<li>Team awareness (to keep a pulse on what else is going on within your
team).</li>
<li>Finding alternative solutions (maybe there&rsquo;s a small change that lets
us kill two birds with one stone).</li>
</ul>


<p>If this is different from how you think about code review, <a href="https://www.youtube.com/watch?v=PJjmw9TRB7s">check out
this talk</a>. Code review is a powerful tool for
learning and growing a team.</p>

<p>With that out of the way, let&rsquo;s dive into the tools I use to maximize
benefit I get from code review.</p>

<h2>Checking out the code</h2>

<p>The first step to reviewing code in the terminal is to check out the
code in the first place. One option is to simply to <code>git pull</code> and then
<code>git checkout &lt;branch&gt;</code>. But if you happen to be using GitHub, we can
get this down to just one command:</p>

<pre><code>hub pr checkout &lt;pr-number&gt;
</code></pre>

<p>It works using <a href="https://github.com/github/hub">hub</a>, which is a tool that exposes various features of
GitHub from the command line. If the pull request is from someone else&rsquo;s
fork, <code>hub</code> is even smart enough to add their fork as a remote and fetch
it.</p>

<h2>At first glance</h2>

<p>With the branch checked out locally, usually my next step is to get a
feel for what changed. For this, I&rsquo;ve written a git alias that shows:</p>

<ul>
<li>which files changed</li>
<li>how many lines changed in each file (additions and deletions)</li>
<li>how many lines changed overall</li>
</ul>


<p><a class="image-link" href="/images/git-stat.png"><img class="fullwidth" src="/images/git-stat.png" title="git stat" ></a></p>

<p>Here&rsquo;s the definition of <code>git stat</code> from my <code>~/.gitconfig</code>:</p>

<pre><code class="bash">[alias]
    # list files which have changed since REVIEW_BASE
    # (REVIEW_BASE defaults to 'master' in my zshrc)
    files = !git diff --name-only $(git merge-base HEAD \"$REVIEW_BASE\")

    # Same as above, but with a diff stat instead of just names
    # (better for interactive use)
    stat = !git diff --stat $(git merge-base HEAD \"$REVIEW_BASE\")
</code></pre>

<p>Under the hood, it just works using <code>git diff</code>, <code>git merge-base</code>, and a
personal environment variable <code>REVIEW_BASE</code>.</p>

<p><code>REVIEW_BASE</code> lets us choose which branch to review relative to. Most of
the time, <code>REVIEW_BASE</code> is <code>master</code>, but this isn&rsquo;t always the case! Some
repos branch off of <code>gh-pages</code>. Sometimes I like to review the most
recent commit as if it were its own branch.</p>

<p>To review the code relative so some other base, set <code>REVIEW_BASE</code> before
running <code>git stat</code>:</p>

<pre><code class="bash"># Review between 'gh-pages' and the current branch
REVIEW_BASE=gh-pages git stat

# Review changes made by the last commit of this branch:
REVIEW_BASE=HEAD^ git stat
</code></pre>

<p>I have <code>export REVIEW_BASE=master</code> in my <code>~/.bashrc</code>, because most
projects branch off of <code>master</code>.</p>

<p>Nothing too crazy yet&mdash;GitHub can already do everything we&rsquo;ve seen so
far. Let&rsquo;s start to up the ante.</p>

<h2>Visualizing file change frequency</h2>

<p>I&rsquo;ve written a short script that shows me a visualization of how
frequently the files involved in this branch change over time:</p>

<p><a class="image-link" href="/images/git-heatmap.png"><img class="fullwidth" src="/images/git-heatmap.png" title="git heatmap" ></a></p>

<p>This command identifies two main things:</p>

<ul>
<li><p><strong>Files with lots of changes</strong>.</p>

<p>Files that have changed a lot in the past are likely to change in the
future. I review these files with an eye towards what the <em>next</em>
change will bring.</p>

<p><em>&ldquo;Is this change robust enough to still be useful in the future?
Will we throw this out soon after merging it?&rdquo;</em></p></li>
<li><p><strong>Files with few changes</strong>.</p>

<p>Files that aren&rsquo;t changed frequently are more likely to be brittle.
Alternatively, it&rsquo;s often the case that infrequently changed files
stay unchanged because the change is better made elsewhere.</p>

<p><em>&ldquo;Does this change challenge an implicit assumption so that some other
part of the code was relying on? Is there a better place for this
change?&rdquo;</em></p></li>
</ul>


<p>Those two commands (<code>git stat</code> and <code>git heatmap</code>) are how I kick off my
code review: getting a birds-eye view of the change and some historical
context for what I&rsquo;m dealing with. Next, I drill down into the
relationships between the files that changed.</p>

<h2>Visualizing relationships between files</h2>

<p>At work I review JavaScript files, so I&rsquo;ve built out this next bit of
tooling specifically for JavaScript.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> It helps to understand
which files import others, so I have a command that computes the
dependency graph of the files changed on this branch:</p>

<p><a class="image-link" href="/images/git-depgraph.png"><img class="fullwidth" src="/images/git-depgraph.png" title="git depgraph" ></a></p>

<p>This is where we start to see some distinct advantages over what GitHub
provides. As you see above, the <code>git depgraph</code> alias calculates the
dependency graph for files changed by this branch. Why is this useful?</p>

<ul>
<li><p>Maybe we want to start reviewing from <code>Provider.js</code>, since it doesn&rsquo;t
depend on any other files that have changed.</p></li>
<li><p>Maybe we want to work the other way: start with <code>Elements.js</code> so we
know the motivation for why <code>Provider.js</code> had to changed in the first
place.</p></li>
</ul>


<p>In either case, we can see the structure of the change. Three files
depend on <code>Elements.js</code>, so it&rsquo;s serving the needs of many modules.
<code>Element.js</code> only has one dependency, etc. Each branch&rsquo;s dependency
graph shows different information; it can be surprising what turns up.</p>

<p>I have the <code>git depgraph</code> alias defined like this:</p>

<pre><code class="bash">[alias]
    depgraph = !git madge image --webpack-config webpack.config.js --basedir . --style solarized-dark src
</code></pre>

<p>Some notes about this definition:</p>

<ul>
<li><p>It depends on the <code>git-madge</code> command, which you can <a href="https://github.com/jez/git-madge">download
and install here</a>.</p></li>
<li><p>It&rsquo;s using <em>this project&rsquo;s</em> <code>webpack.config.js</code> file, so I&rsquo;ve made
this alias local to the repo, rather than available globally.</p></li>
<li><p>It dumps the image to stdout. Above, we used iTerm2&rsquo;s <a href="https://iterm2.com/documentation-images.html">imgcat</a>
program to pipe stdin and dump a raster image to the terminal.</p>

<p>If you don&rsquo;t use iTerm2 or don&rsquo;t want to install <code>imgcat</code>, you can
pipe it to Preview using open<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> (<code>open -f -a Preview</code>) or just
redirect the PNG to a file.</p></li>
</ul>


<p>The <code>git depgraph</code> alias is a game changer. It makes it easier to get spun
up in new code bases, helps make sense of large changes, and just looks
plain cool. But at the end of the day, we came here to review some code,
so let&rsquo;s take a look at how we can actually view the diffs of the files
that changed.</p>

<h2>Reviewing the diffs</h2>

<p>To review the diffs, the simplest option is to just run <code>git diff
master..HEAD</code>. This has a bunch of downsides:</p>

<ul>
<li><p>No syntax highlighting (everything is either green or red).</p></li>
<li><p>No surrounding context (for example, GitHub lets you click to expand
lines above or below a diff hunk).</p></li>
<li><p>The diff is &ldquo;unified,&rdquo; instead of split into two columns.</p></li>
<li><p>No way to exclude a specific file (the 300 line diff to your
<code>yarn.lock</code> file is sometimes nice to hide).</p></li>
</ul>


<p>My solution to all of these problems is to view the diffs in Vim, with
the help of two Vim plugins and two git aliases. Before we get to
that, here&rsquo;s a screenshot:</p>

<p><a class="image-link" href="/images/git-review.png"><img class="fullwidth" src="/images/git-review.png" title="git review" ></a></p>

<p>Looks pretty similar to GitHub&rsquo;s interface, with the added bonus that
it&rsquo;s using my favorite colorscheme! The Vim plugins featured are:</p>

<ul>
<li><a href="https://github.com/tpope/vim-fugitive">tpope/vim-fugitive</a> for showing the side-by-side diff (<code>:Gdiff</code>).</li>
<li><a href="https://github.com/airblade/vim-gitgutter">airblade/vim-gitgutter</a> for showing the <code>+/-</code> signs.</li>
<li><a href="https://github.com/jez/vim-colors-solarized">jez/vim-colors-solarized</a> for tweaking the diff highlight
colors.<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup></li>
</ul>


<p>And to orchestrate the whole thing, I&rsquo;ve set up these two aliases:</p>

<pre><code class="bash">[alias]
  # NOTE: These aliases depend on the `git files` alias from
  # a few sections ago!

    # Open all files changed since REVIEW_BASE in Vim tabs
    # Then, run fugitive's :Gdiff in each tab, and finally
    # tell vim-gitgutter to show +/- for changes since REVIEW_BASE
    review = !vim -p $(git files) +\"tabdo Gdiff $REVIEW_BASE\" +\"let g:gitgutter_diff_base = '$REVIEW_BASE'\"

    # Same as the above, except specify names of files as arguments,
    # instead of opening all files:
    # git reviewone foo.js bar.js
    reviewone = !vim -p +\"tabdo Gdiff $REVIEW_BASE\" +\"let g:gitgutter_diff_base = '$REVIEW_BASE'\"
</code></pre>

<p>Here&rsquo;s how they work:</p>

<ul>
<li><p><code>git review</code> opens each file changed by this branch as a tab in Vim.
Then <code>:Gdiff</code> from vim-fugitive shows the diff in each tab.</p></li>
<li><p><code>git reviewone</code> is like <code>git review</code>, but you specify which
files to open (in case you only want to diff a few).</p></li>
</ul>


<p>Like with the <code>git stat</code> alias, these aliases respect the <code>REVIEW_BASE</code>
environment variable I&rsquo;ve set up in my <code>~/.bashrc</code>. (Scroll back up for
a refresher.) For example, to review all files relative to <code>master</code>:</p>

<pre><code class="bash">REVIEW_BASE=master git review
</code></pre>

<p>At this point, you might think that all we&rsquo;ve done is re-create the
GitHub code review experience in Vim. But actually what we&rsquo;ve done is so
much more powerful.</p>

<h2>Interactive Code Review</h2>

<p>When reviewing on GitHub, the code is completely static&mdash;you can&rsquo;t
change it. Also, because the code is coming from GitHub&rsquo;s servers,
it&rsquo;s laggy when you click around to view related files. By switching our
code review to the terminal, we can now edit files, jump to other files,
and run arbitrary commands at no cost.</p>

<p>It might not be obvious how huge of a win this is, so let&rsquo;s see some
examples. Take this screenshot of the <code>requireElement</code> function. It
moved from <em>above</em> the <code>findElement</code> function to <em>below</em> it (probably
because the former calls the latter):</p>

<p><a class="image-link" href="/images/requireElement01.png"><img class="fullwidth" src="/images/requireElement01.png" title="diff" ></a></p>

<p>But is the location of the <code>requireElement</code> function the only thing
that&rsquo;s changed? By editing the file to move the function back to its
original location, vim-fugitive will automatically recompute the diff.
And in fact, we can see that the <em>type of the argument</em> has changed too,
from <code>string</code> to <code>ElementType</code>:</p>

<p><a class="image-link" href="/images/requireElement02.png"><img class="fullwidth" src="/images/requireElement02.png" title="diff" ></a></p>

<p>If we had been viewing this on GitHub, we might have taken for granted
that the function didn&rsquo;t change. But since we&rsquo;re in our editor, we can
interactively play around with our code and discover things we might
have missed otherwise. The advantages of interactive code review go well
beyond this example:</p>

<ul>
<li><p>In a Flow project, we can ask for the type of a variable.</p></li>
<li><p>In a test file, we can change the test and see if it still passes or
if it now fails.</p></li>
<li><p>We can <code>grep</code> the project for all uses of a function (including files
<em>not</em> changed by this branch).</p></li>
<li><p>We can open up related files for cross-referencing.</p></li>
<li><p>We can run the code in a debugger and see how it behaves.</p></li>
</ul>


<p>By having the full power of our editor, we can literally retrace the
steps that the author went through to create the pull request. If our
goal is to understand and learn from code review, there&rsquo;s no better way
than walking in the author&rsquo;s shoes.</p>

<h2>Recap</h2>

<p>To recap, here&rsquo;s a list of the tools I use to review code at the command
line:</p>

<ul>
<li><code>hub pr checkout</code></li>
<li><code>git stat</code> to list files that have changed</li>
<li><code>git heatmap</code> to show how frequently these files change</li>
<li><code>git depgraph</code> to show a graph of which files depend on which</li>
<li><code>git review</code> to open diffs of all the files in Vim</li>
<li><code>git reviewone</code> to open diffs for a specific handful of files</li>
</ul>


<p>If you&rsquo;re having trouble incorporating any of these into your workflow,
feel free to reach out and let me know! I&rsquo;m happy to help.</p>

<!-- vim:tw=72
-->

<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>The techniques here apply to any language that you can statically analyze. In particular, I have a rough prototype of everything JavaScript-specific you see here that works with Standard ML instead. If you can find me the dependency information for your favorite language, I&rsquo;d be happy to help you turn it into a visualization.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>The <code>open</code> command is macOS-specific. On Linux, you might want to look at the <code>display</code> command from ImageMagick.<a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p>I&rsquo;ve patched the default Solarized colors for Vim so that lines retain their syntax highlighting in the diff mode, while the backgrounds are highlighted. You can see how this works in this commit: <a href="https://github.com/jez/vim-colors-solarized/commit/bca72cc">https://github.com/jez/vim-colors-solarized/commit/bca72cc</a><a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Show where a Python package is used]]></title>
    <link href="https://blog.jez.io/2015/06/12/show-where-a-python-package-is-used/"/>
    <updated>2015-06-12T02:36:05-04:00</updated>
    <id>https://blog.jez.io/2015/06/12/show-where-a-python-package-is-used</id>
    <content type="html"><![CDATA[<p>A while back I was doing some spring cleaning of my Python packages. I noticed
that there were a bunch of packages that I couldn&rsquo;t recall installing. I wanted
to know if I could safely remove them, so I wrote a simple bash script to tell
me called <code>pip-uses</code>.</p>

<!-- more -->


<h2>Source</h2>

<p>Rather than post the source here and let it get more out of date every time I
change it, you can find the source <a href="https://github.com/jez/bin/blob/master/pip-uses">on GitHub</a>. It&rsquo;s in my <a href="https://github.com/jez/bin">bin
repository</a>, where I keep my notable helper scripts; feel free to
poke around.</p>

<h2>Motivations</h2>

<p>I was primarily influenced by Homebrew&rsquo;s <code>brew uses</code> command. It does a nice job
of giving you exactly the information you want, and I think the way the command
is named makes sense.</p>

<pre><code class="plain Homebrew: brew uses">$ brew uses --installed pango
imagemagick
</code></pre>

<p><code>pip-uses</code> gives you basically the experience:</p>

<pre><code class="plain Pip: pip-uses">$ pip-uses stevedore
virtualenvwrapper
</code></pre>

<p>In this example, the Python package <code>virtualenvwrapper</code> uses <code>stevedore</code>, just
as <code>imagemagick</code> uses <code>pango</code>. Both commands can save you from accidentally
removing a crucial dependency and answer the burning question, &ldquo;How in the world
did this thing get installed?&rdquo;</p>

<h2>Wish List</h2>

<p>I&rsquo;m not doing much Python development these days, but if I had some spare time
I&rsquo;d love for the script to also have these features:</p>

<ul>
<li>Recursive enumeration of dependencies

<ul>
<li>It&rsquo;d be nice if <code>pip-uses</code> kept recursively searching until it found no more
dependencies. This way, it&rsquo;d be easy to see if you could safely uninstall a
whole slew of packages that you&rsquo;re no longer using.</li>
</ul>
</li>
<li>Operate on more than one package

<ul>
<li>I didn&rsquo;t need it at the time, so I didn&rsquo;t implement it, but it&rsquo;d be nice if
the command took a variable amount of arguments and ran the same logic on
all supplied packages.</li>
</ul>
</li>
<li>Integrate with <code>pip</code>

<ul>
<li>Programs like <code>brew</code> and <code>pip</code> allow developers to add &ldquo;external commands&rdquo;
by adding commands to the <code>PATH</code> that look like <code>brew-xyz</code> or <code>git-xyz</code>. I
couldn&rsquo;t find if there was a special way to add external commands to <code>pip</code>.</li>
</ul>
</li>
</ul>


<p>If you find this script useful and end up implementing one of these feature or
more on top of <code>pip-uses</code>, be sure to send me a Pull Request!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Google Chrome: A Memory Hog]]></title>
    <link href="https://blog.jez.io/2014/12/29/google-chrome-a-memory-hog/"/>
    <updated>2014-12-29T18:00:00-05:00</updated>
    <id>https://blog.jez.io/2014/12/29/google-chrome-a-memory-hog</id>
    <content type="html"><![CDATA[<p>Whenever someone complains about a slow computer, the first thing I check is
how many Chrome tabs they have open. Chrome hogs memory like no other. For
users, this means Chrome is snappy and responsive, but oftentimes it comes at
the expense of crowding out other programs. To get an idea of how much memory
Chrome is really using, I wrote a quick bash oneliner.</p>

<!-- more -->


<h2>Why does Chrome Hog Memory?</h2>

<p><a href="http://mobile.extremetech.com/latest/221392-iframe-irony-adblock-plus-is-probably-the-reason-firefox-and-chrome-are-such-memory-hogs">An article posted to Hacker News</a> recently brought some light to
the question of why Chrome and Firefox suck up so much memory: Adblock Plus. The
general idea is that the excessive use of iframes in most websites today ramps
up the amount of processing that Adblock Plus has to do, driving memory usage
through the roof. For more specifics, check out the rest of of the article.</p>

<h2>The Oneliner</h2>

<p>For the impatient, here&rsquo;s the code. It uses standard Unix tools:</p>

<pre><code class="bash Chrome Memory Usage">$ ps -ev | grep -i chrome | awk '{print $12}' | awk '{for(i=1;i&lt;=NF;i++)s+=$i}END{print s}'
</code></pre>

<p>Pretty isn&rsquo;t it? If you want to save this as an alias for handy use, add this
line to your ~/.bashrc (or appropriate configuration file):</p>

<pre><code class="bash Add as an alias">alias chromemem="ps -ev | grep -i chrome | awk '{print \$12}' | awk '{for(i=1;i&lt;=NF;i++)s+=\$i}END{print s}'"
</code></pre>

<p>It outputs a percentage. Here&rsquo;s the alias in action:</p>

<pre><code class="bash Usage">$ chromemem
60
</code></pre>

<h2>Explanation</h2>

<p>There&rsquo;s a lot of good stuff going on here, so let&rsquo;s take it step-by-step.</p>

<p>First, we&rsquo;ll need a program that tells us memory usage. I&rsquo;m sure there are many,
but I&rsquo;m familiar with <code>ps</code>. After checking out the man page for a few options, I
came up with <code>ps -ev</code>, to show all information about all processes. Maybe
wasteful, but it works.</p>

<pre><code class="bash ps -ev">$ ps -ev
  PID STAT      TIME  SL  RE PAGEIN      VSZ    RSS   LIM     TSIZ  %CPU %MEM COMMAND
 3473 S      0:54.92   0   0      0  3579092 301244     -        0   6.7  7.2 /Applications/Google C
  365 S      3:03.17   0   0      0  3920732 206808     -        0   0.3  4.9 /Applications/Google C
  983 S      1:29.23   0   0      0  3560272 193860     -        0   0.1  4.6 /Applications/Google C
  395 S      0:13.11   0   0      0  2824936 141644     -        0   0.0  3.4 /Applications/Google C
  422 S      0:27.22   0   0      0  3345796 130796     -        0   0.0  3.1 /Applications/Google C
  ...
</code></pre>

<p>Notice that there&rsquo;s a convenient column describing memory usage as a percentage
of total available memory, as well as what command is being run in that
process. Let&rsquo;s make sure that we&rsquo;re looking at only the processes running
some sort of Chrome service before totaling up the memory. We can find these
lines with <code>ps -ev | grep -i chrome</code> (the -i means case-insensitive). Due to the
way I clipped the previous sample output, nothing changes in the first five
lines, but rest assured: we&rsquo;re only looking at Chrome processes now.</p>

<p>Now it&rsquo;s time to get rid of all the other nonsense that we included with <code>ps
-ev</code>. Luckily, there&rsquo;s a handy tool called <code>awk</code> that makes parsing text by
column easy. If we want to print the 12th column (which just so happens to
contain the memory consumption!) we can do <code>awk '{print $12}'</code>:</p>

<pre><code class="bash ps -ev | grep -i chrome | awk '{print $12}'">$ ps -ev | grep -i chrome | awk '{print $12}'
7.2
5.1
4.6
3.4
3.2
...
</code></pre>

<p>Finally, I found myself needing a way to add up a column of numbers. A quick
Google search led me to <a href="http://stackoverflow.com/questions/2572495/read-from-file-and-add-numbers">this StackOverflow question</a>, and I picked the
<code>awk</code> solution because I knew I could just pipe the input to awk (as opposed to
having to do weird hacks to get it to work with a bash for loop):</p>

<pre><code class="bash Final Solution">$ ps -emv | grep -i chrome | awk '{print $12}' | awk '{for(i=1;i&lt;=NF;i++)s+=$i}END{print s}'
60.4
</code></pre>

<p>Of course, you could change the last <code>awk</code> command to print out something
fancier like</p>

<pre><code class="bash Final Solution">$ ps -emv | grep -i chrome | awk '{print $12}' | awk '{for(i=1;i&lt;=NF;i++)s+=$i}END{print "Chrome is using "s"% of total memory."}'
Chrome is using 60.4% of total memory.
</code></pre>

<p>There you have it! Bash oneliners save the day yet again.</p>

<h2>Update</h2>

<p>After writing this article, I stopped using Ad Block Plus, and I noticed a
significant drop in Chrome&rsquo;s memory usage. Obviously, though, that came at the
cost of not blocking ads! Also, from time to time I would encounter a site that
seemed sluggish, presumably because of all the ads attempting to be loaded. My
simple solution to this was just to disable JavaScript on that page (I use an
extension called Quick JavaScript Switcher), but this wasn&rsquo;t an automated
solution.</p>

<p>Then I discovered <a href="https://github.com/gorhill/uBlock">μBlock</a>, an &ldquo;efficient blocker for Chromium and
Firefox.&rdquo; The fancy graphs on it&rsquo;s homepage convinced me to give it a shot, and
from what I can tell so far it&rsquo;s responsive and effective.</p>
]]></content>
  </entry>
  
</feed>

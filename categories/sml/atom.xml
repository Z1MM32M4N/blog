<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: sml | Bits, Bytes, and Words]]></title>
  <link href="https://blog.jez.io/categories/sml/atom.xml" rel="self"/>
  <link href="https://blog.jez.io/"/>
  <updated>2019-06-13T12:21:12-04:00</updated>
  <id>https://blog.jez.io/</id>
  <author>
    <name><![CDATA[Jake Zimmerman]]></name>
    <email><![CDATA[jake@zimmerman.io]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Standard ML in Travis&nbsp;CI]]></title>
    <link href="https://blog.jez.io/sml-travis-ci/"/>
    <updated>2019-06-04T12:26:45-04:00</updated>
    <id>https://blog.jez.io/sml-travis-ci</id>
    <content type="html"><![CDATA[<p>For one of my recent projects (<a href="https://github.com/jez/multi-grep"><code>multi-grep</code></a>) I went through the work to
get Standard ML building in Travis CI. It turned out to be not too
hard—in fact, the hardest part is already done, and I&rsquo;m happy to share
how it works.</p>

<!-- more -->


<h2>Features</h2>

<p>The way I set up my builds, I can:</p>

<ul>
<li>build and test with both macOS and Linux</li>
<li>build and test with both SML/NJ and MLton</li>
<li>create executables, even with SML/NJ</li>
<li>publish the resulting builds to GitHub as releases</li>
</ul>


<p>Apart from some scripts to install things on each operating system,
under the hood it&rsquo;s powered by <a href="https://github.com/jez/symbol">Symbol</a>, which is a build tool for
Standard ML I wrote which factors out most of the project-agnostic
stuff.</p>

<h2>The core setup</h2>

<p>Rather than paste the code into a snippet here and wait for it to get
out of date, see my <a href="https://github.com/jez/multi-grep"><code>multi-grep</code></a> project on GitHub for all the
up-to-date files. In total, there are three files in that repo which set
the whole thing up:</p>

<ol>
<li><a href="https://github.com/jez/multi-grep/blob/b6a42719b1ffca389556655982e6c4b7fa19c9a1/.travis.yml">.travis.yml</a> (kicks off the build)</li>
<li><a href="https://github.com/jez/multi-grep/blob/b6a42719b1ffca389556655982e6c4b7fa19c9a1/Brewfile">Brewfile</a> (deps for macOS build)</li>
<li><a href="https://github.com/jez/multi-grep/blob/b6a42719b1ffca389556655982e6c4b7fa19c9a1/tests/travis-install.sh">tests/travis-install.sh</a> (deps for Linux build)</li>
</ol>


<p>If you haven&rsquo;t used Travis CI before, you&rsquo;ll probably also want to check
out the <a href="https://docs.travis-ci.com/">Travis CI docs</a> to get a feel for how to actually set things
up, and where these pieces fit in.</p>

<h2>Why write a whole build tool?</h2>

<p>I mentioned above that I&rsquo;d written a build tool for Standard ML, called
<a href="https://github.com/jez/symbol">Symbol</a>. Why? It started as a shell script + <code>Makefile</code> for
<a href="https://github.com/jez/multi-grep"><code>multi-grep</code></a> and then I realized that these scripts could be useful in
any Standard ML project.</p>

<p>SML/NJ and MLton are already great compilers with their own build tools.
It&rsquo;s useful to be able to build a project with both (SML/NJ for faster
builds and a REPL, and MLton for faster compiled executables). All
Symbol really does is put SML/NJ and MLton behind a unified, very
stripped down interface.</p>

<p>There&rsquo;s more information <a href="https://github.com/jez/symbol">in the README</a>, but some key points:</p>

<ul>
<li>Symbol makes it easy to build and install executables, even with
SML/NJ which traditionally uses heap images.</li>
<li>Symbol is built on <code>make</code>, so if <strong>no</strong> source files change, even
recompiling with MLton is instant.</li>
<li>Symbol also supports scaffolding new Standard ML projects, which is
nicer than starting from scratch.</li>
</ul>


<p>Again, there&rsquo;s way more information <a href="https://github.com/jez/symbol">in the README</a>, so
definitely check it out if you&rsquo;re thinking about setting up a new
Standard ML project. The usage looks something like this:</p>

<pre><code class="bash"># initialize a new project:
❯ symbol-new hello
❯ cd hello

# build with SML/NJ:
❯ ./symbol make
❯ .symbol-work/bin/hello
Hello, world!

# or, build with MLton:
❯ ./symbol make with=mlton
❯ .symbol-work/bin/hello
Hello, world!
</code></pre>

<h2>Why Standard ML in the first place?</h2>

<p>I&rsquo;ll probably get around to writing about <a href="https://github.com/jez/multi-grep"><code>multi-grep</code></a> (and related
tools like <a href="https://github.com/jez/diff-locs"><code>diff-locs</code></a> and <a href="https://github.com/jez/multi-sub"><code>multi-sub</code></a>) but at the end of the day:
SML is a really pleasant language to use in a lot of ways:</p>

<ul>
<li>Type inference in Standard ML is a breath of fresh air.</li>
<li>Data types let me wonder less about how things work.</li>
<li>Pattern matching makes for concise, clean, and correct code.</li>
</ul>


<p>Standard ML was my most commonly used programming language throughout
all of my university courses, so there&rsquo;s a definite soft spot in my
heart for it. There are features that I wish it had sometimes, but it&rsquo;s
the only language that I&rsquo;ve used that doesn&rsquo;t feel fundamentally broken
in some way.</p>

<!-- vim:tw=72
-->

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Concurrent Programming in ML: A Race]]></title>
    <link href="https://blog.jez.io/cpml-race/"/>
    <updated>2018-07-18T00:23:23-04:00</updated>
    <id>https://blog.jez.io/cpml-race</id>
    <content type="html"><![CDATA[<p>Lately I&rsquo;ve been super interested in language models for concurrency,
after hearing a fascinating talk from Adam Solove on <a href="https://medium.com/@asolove/synchronizable-abstractions-for-understandable-concurrency-64ae57cd61d1">synchronizable
abstractions for UI</a>.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> I&rsquo;ve been working my way through a
handful of books, including <a href="https://simonmar.github.io/pages/pcph.html">PCPH</a>, the Concurrency section of <a href="http://www.cs.cmu.edu/~rwh/pfpl.html">PFPL</a>,
and most recently <a href="http://www.cambridge.org/gb/academic/subjects/computer-science/distributed-networked-and-mobile-computing/concurrent-programming-ml?format=AR">Concurrent Programming in ML</a>, by John Reppy.</p>

<p>In particular, I think I&rsquo;ve found a race condition in one of the code
listings of Concurrent Programming in ML. After introducing the listing
itself, we&rsquo;ll walk through a trace that shows the errant behavior, then
propose a small change that prevents it from happening.</p>

<h2>Setup: Snippets from the Book</h2>

<p>Before we begin, here&rsquo;s the listing in full. It&rsquo;s a sample
implementation of a 1-element concurrent buffer, using condition
variables. It supports creation, insertion, and removal.</p>

<pre><code class="sml Concurrent Programming in ML, Listing 2.3">datatype 'a buffer = BUF of {
  data      : 'a option ref,
  mu        : mutex,
  dataAvail : condition,
  dataEmpty : condition
}

fun buffer () =
  let val mu = mutex() in
    BUF {
      data      = ref NONE,
      mu        = mu,
      dataAvail = condition mu,
      dataEmpty = condition mu
    }
  end

fun insert (BUF {data, mu, dataAvail, dataEmpty}, v) =
  let
    fun waitLp NONE = (data := SOME v; signal dataAvail)
      | waitLp (SOME v) = (wait dataEmpty; waitLp (!data))
  in
    withLock mu waitLp (!data)
  end

fun remove (BUF {data, mu, dataAvail, dataEmpty}) =
  let
    fun waitLp NONE = (wait dataAvail; waitLp (!data))
      | waitLp (SOME v) = (data := NONE; signal dataEmpty)
  in
    withLock mu waitLp (!data)
  end
</code></pre>

<p>You might also want to reference this exerpt which explains the
semantics of the concurrency primitives at play in the snippet above:
locks and condition variables. Study the listing above and exerpt below
for a moment. See if you can spot a race, or are convinced the code is
correct.</p>

<blockquote><p>The semantics of the expression</p>

<p><code>withLock mu f x</code></p>

<p>are that first the lock mu is acquired, then the function f is applied
to x, and then the function&rsquo;s result is returned after releasing the
lock.</p>

<p>The basic operations on condition variables are</p>

<p><code>val wait : condition -&gt; unit</code></p>

<p>which causes a process to block on the condition variable, and</p>

<p><code>val signal : condition -&gt; unit</code></p>

<p>which wakes up one waiting process. A condition variable is associated
with a specific mutex lock, which must be held when performing a wait
operation on the variable. The semantics of the wait operation are
that the mutex lock is released, and then the process is blocked; when
the condition is signaled, the next process in the condition&rsquo;s waiting
queue is unblocked and it reacquires the mutex lock and proceeds. A
signal operation on a condition variable that has an empty waiting
queue has no effect; in this sense condition variables are memoryless.</p>

<p>&mdash; <em>Concurrent Programming in ML</em>, section 2.4.2</p></blockquote>

<h2>A trace to expose the problem</h2>

<p>The problem I see has to do with SML&rsquo;s eager evaluation: before calling
a function <code>f e</code>, we evaluate <code>e</code> to a value <code>v</code>. Then substitution
kicks in and we substitute <code>v</code> into the body of <code>f</code>. For us,
that means that in the definition of <code>insert</code>:</p>

<pre><code class="sml">fun insert (* ··· *) =
  (* ··· *)
    withLock mu waitLp (!data)
  (* ··· *)
</code></pre>

<p>we evaluate <code>!data</code> to a value before we run the body of <code>withLock</code> to
acquire the lock. When inserting into an empty queue, <code>!data</code> evaluates
to <code>NONE</code>. And since this happens outside the <code>withLock</code> if two calls to
insert attempt to acquire the lock at the same time, they&rsquo;ll both think
the queue is empty when they wake up! When this happens, the one to wake
up second will unknowingly overwrite what the first one inserted.</p>

<p>Here&rsquo;s a sample trace of a program allocating a buffer and then
doing two concurrent insertions:</p>

<pre><code class="sml Sample trace, showing that first insert gets dropped">(* '=&gt;' marks steps where two threads evolve concurrently  *)
(* '-&gt;' marks steps where just one thread evalautes        *)

-&gt; val buf = buffer ()

(* Fork two threads; both have access to 'buf'.            *)

   (* thread 1 *)                       (* thread 2 *)
=&gt; insert buf 1                         insert buf 2
=&gt; withLock mu waitLp (!data)           withLock mu waitLp (!data)
=&gt; withLock mu waitLp NONE              withLock mu waitLp NONE

   (* thread 1 acquires lock *)
-&gt; waitLp NONE
-&gt; (data := SOME v; signal dataAvail)
-&gt; (data := SOME 1; signal dataAvail)
   (* {data = ref (SOME 1), ...} *)
-&gt; ((); signal dataAvail)
-&gt; signal dataAvail
-&gt; ()
   (* thread 1 releases lock *)

                                        (* thread 2 acquires lock *)
                                        (* NONE is now stale! *)
-&gt;                                      waitLp NONE
                                        (* selects wrong case in function *)
-&gt;                                      (data := SOME v; signal dataAvail)
-&gt;                                      (data := SOME 2; signal dataAvail)
                                        (* ==&gt; data = ref (SOME 2) *)
-&gt;                                      ((); signal dataAvail)
-&gt;                                      signal dataAvail
-&gt;                                      ()
</code></pre>

<p>Notice how the stale read allowed two consecutive inserts. What we
wanted was for the second insert to wake up, see that the buffer is
full, then wait for the <code>dataEmpty</code> condition variable to wake it up.
So having the <code>!data</code> outside the lock is not good.</p>

<h2>Fixing the stale read</h2>

<p>The solution to this is to delay evaluating <code>!data</code> until the body of the
<code>waitLp</code> function, which only executes when we have the lock. This
ensures that we don&rsquo;t read a stale value for the content of the buffer.</p>

<pre><code class="sml Listing 2.3, updated to avoid race">datatype 'a buffer = (* ··· *)
fun buffer () = (* ··· *)

fun insert (BUF {data, mu, dataAvail, dataEmpty}, v) =
  let
    (* !data is now within waitLp, so it's never stale. *)
    fun waitLp () =
      case !data
        of NONE =&gt; (data := SOME v; signal dataAvail)
         | SOME v =&gt; (wait dataEmpty; waitLp ())
  in
    withLock mu waitLp ()
  end

fun remove (BUF {data, mu, dataAvail, dataEmpty}) =
  let
    fun waitLp () =
      case !data
        of NONE =&gt; (wait dataAvail; waitLp ())
         | SOME v =&gt; (data := NONE; signal dataEmpty)
  in
    withLock mu waitLp ()
  end
</code></pre>

<p>Pretty small bug, and it doesn&rsquo;t detract from the main point of the
listing, which is to show how to use condition variables in a sort of
&ldquo;mutually recursive&rdquo; style where <code>dataEmpty</code> wakes up <code>insert</code> which
signals on <code>dataAvail</code> which wakes up <code>remove</code>.</p>

<p>This also underscores how difficult it really is to ensure correctness
in the presence of concurrency! That&rsquo;s exactly why I&rsquo;ve been reading
about all these language models for concurrency, to better understand
how we can leverage our programming language to ensure our programs are
correct by construction.</p>

<!-- vim:tw=72
-->

<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Unfortunately, the talk isn&rsquo;t online (Adam presented it at work), so the blog post linked above is the next best thing!<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[System Fω and Parameterization]]></title>
    <link href="https://blog.jez.io/system-f-param/"/>
    <updated>2017-09-27T22:14:45-04:00</updated>
    <id>https://blog.jez.io/system-f-param</id>
    <content type="html"><![CDATA[<p>When I first learned about System F<sub>ω</sub>, I was confused about
the difference between <code>∀(t.τ)</code> (forall types) and <code>λ(u.c)</code> (type
abstractions) for a long time, but recently I finally grasped the
difference! Both of these constructs have to do with parameterization
(factoring out a variable so that it&rsquo;s bound), but the two types have
drastically different meanings.</p>

<!-- more -->


<h2>Questions</h2>

<p>We&rsquo;ll start off with some questions to keep in mind throughout these
notes. Our goals by the end are to understand what the questions are
asking, and have at least a partial&mdash;if not complete&mdash;answer to each.</p>

<p>First, consider this code.</p>

<pre><code class="sml">datatype 'a list = Nil | Cons of 'a * 'a list
</code></pre>

<ul>
<li>What really is &ldquo;<code>list</code>&rdquo; in this code?</li>
<li>Or put another way, how would we define <code>list</code> in System
F<sub>ω</sub>?</li>
</ul>


<p>Thinking more broadly,</p>

<ul>
<li>What separates <code>∀(t.τ)</code> and <code>λ(u.c)</code>?</li>
<li>What is parameterization, and how does it relate to these things?</li>
</ul>


<h2>System F<sub>ω</sub></h2>

<p>The answers to most of these questions rely on a solid definition of
System F<sub>ω</sub>. We&rsquo;ll be using this setup.</p>

<pre><code>Kind κ ::= * | κ → κ | ···

           abstract       concrete      arity/valence
Con c  ::= ···
         | arr(c₁; c₂)    c₁ → c₂       (Con, Con)Con
         | all{κ}(u.c)    ∀(u ∷ κ). c   (Kind, Con.Con)Con
         | lam{κ}(u.c)    λ(u ∷ κ). c   (Kind, Con.Con)Con
         | app(c₁; c₂)    c₁(c₂)        (Con, Con)Con
</code></pre>

<p>Some points to note:</p>

<ul>
<li><code>∀(u ∷ κ). c</code> and <code>λ(u ∷ κ). c</code> have the same arity.</li>
<li><code>∀(u ∷ κ). c</code> and <code>λ(u ∷ κ). c</code> both <em>bind</em> a constructor variable.
This makes these two operators <em>parametric</em>.</li>
<li>Only <code>λ(u ∷ κ). c</code> has a matching elim form: <code>c₁(c₂)</code>.
(There are no elim forms for <code>c₁ → c₂</code> and <code>∀(u ∷ κ). c</code>, because they
construct types of kind <code>*</code>. This will be important later.)</li>
</ul>


<p>It&rsquo;ll also be important to have these two inference rules for kinding:</p>

<p>$$
\frac{
  \Delta, u :: \kappa \vdash c :: *
}{
  \Delta \vdash \forall(u :: \kappa). \, c :: *
}\;(\texttt{forall-kind})
$$
$$
\frac{
  \Delta, u :: \kappa \vdash c :: \kappa&#8217;
}{
  \Delta \vdash \lambda(u :: \kappa). \, c :: \kappa \to \kappa&#8217;
}\;(\texttt{lambda-kind})
$$</p>

<h2>Defining the <code>list</code> Constructor</h2>

<p>Let&rsquo;s take another look at this datatype definition from above:</p>

<pre><code class="sml">datatype 'a list = Nil | Cons of 'a * 'a list
</code></pre>

<p>We&rsquo;ve <a href="/variables-in-types/">already seen</a> how to encode the type of lists
of integers using inductive types:</p>

<pre><code>intlist = μ(t. 1 + (int × t))
</code></pre>

<p>Knowing what we know about System F (the &ldquo;<strong>polymorphic</strong> lambda
calculus&rdquo;), our next question should be &ldquo;how do we encode
<strong>polymorphic</strong> lists?&rdquo; Or more specifically, which of these two
operators (<code>λ</code> or <code>∀</code>) should we pick, and why?</p>

<p>First, we should be more specific, because there&rsquo;s a difference between
<code>list</code> and <code>'a list</code>. Let&rsquo;s start off with defining <code>list</code> in
particular. From what we know of programming in Standard ML, we can do
things like:</p>

<pre><code class="sml">(* Apply 'int' to 'list' function! *)
type grades = int list

type key = string
type val = real

(* Apply '(key, val)' to 'list' function! *)
type updates = (key, val) list
</code></pre>

<p>If we look really closely, what&rsquo;s actually happening here is that <code>list</code>
is a type-level <em>function</em> that returns a type (and we use the <code>type foo
= ...</code> syntax to store that returned type in a variable).<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p>

<p>Since <code>list</code> is actually a function from types to types, it must have
an arrow kind: <code>* → *</code>. Looking back at our two inference rules for
kinding, we see only one rule that lets us introduce an arrow kind: <code>λ(u
∷ κ). c</code>. On the other hand, <code>∀(u ∷ κ). c</code> must have kind <code>*</code>; it
<em>can&rsquo;t</em> be used to define type constructors.</p>

<p>Step 1: define list constructor? Check:</p>

<pre><code>list = λ(α ∷ *). μ(t. 1 + (α × t)))
</code></pre>

<h2>Defining Polymorphic Lists</h2>

<p>It doesn&rsquo;t stop with the above definition, because it&rsquo;s still not
<em>polymorphic</em>. In particular, we can&rsquo;t just go write functions on
polymorphic lists with code like this:</p>

<pre><code class="sml">fun foo (x : list) = (* ··· *)
</code></pre>

<p>We can&rsquo;t say <code>x : list</code> because all intermediate terms in a given
program have to type check as a type of kind <code>*</code>, whereas <code>list ∷ * →
*</code>. Another way of saying this: there isn&rsquo;t any way to introduce a value
of type <code>list</code> because there&rsquo;s no way to introduce values with arrow
kinds.</p>

<p>Meanwhile, we <em>can</em> write this:</p>

<pre><code class="sml">fun foo (x : 'a list) = (* ··· *)
</code></pre>

<p>When you get down to it, this is actually kind of weird. Why is it okay
to use <code>'a list</code>? I never defined <code>'a</code> anywhere, so wouldn&rsquo;t that make
it an unbound variable?</p>

<p>It turns out that when we use type variables like this, SML
automatically binds them for us by inserting <code>∀</code>s into our code. In
particular, it implicitly infers a type like this:</p>

<pre><code class="sml">val foo : forall 'a. 'a list -&gt; ()
</code></pre>

<p>SML inserts this <code>forall</code> automatically because its type system is a bit
less polymorphic than System F<sub>ω</sub>&rsquo;s. Some might call this a
drawback, though it does save us from typing <code>forall</code> annotations
ourselves. And really, for most anything else we&rsquo;d call a &ldquo;drawback&rdquo; of
this design, SML makes up the difference with modules.<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup></p>

<p>Step 2: make polymorphic list for use in annotation? Check:</p>

<pre><code>α list = ∀(α ∷ *). list(α)
</code></pre>

<h2>Variables &amp; Parameterization</h2>

<p>Tada! We&rsquo;ve figured out how to take a list datatype from SML and encode
it in System F<sub>ω</sub>, using these two definitions:</p>

<pre><code>  list = λ(α ∷ *). μ(t. 1 + (α × t)))
α list = ∀(α ∷ *). list(α)
</code></pre>

<p>We could end here, but there&rsquo;s one more interesting point. If we look
back, we started out with the <code>∀</code> and <code>λ</code> operators having the same
arity, but somewhere along the way their behaviors differed. <code>λ</code> was
used to create type constructors, while <code>∀</code> was used to introduce
polymorphism.</p>

<p>Where did this split come from? What distinguishes <code>∀</code> as being the
go-to type for polymorphism, while <code>λ</code> makes type constructors
(type-to-type functions)? Recall one of the earliest ideas we teach in
<a href="http://www.cs.cmu.edu/~rwh/courses/ppl/">15-312</a>:</p>

<blockquote><p>&hellip; the core idea carries over from school mathematics, namely
that <strong>a variable is an unknown, or a place-holder, whose meaning is
given by substitution.</strong></p>

<p>&ndash; Harper, <em>Practical Foundations for Programming Languages</em></p></blockquote>

<p>Variables are given meaning by substitution, so we can look to the
appropriate substitutions to uncover the meaning and the differences
between <code>λ</code> and <code>∀</code>. Let&rsquo;s first look at the substitution for <code>λ</code>:</p>

<p>$$
\frac{
  \Delta, u :: \kappa_1 \vdash c_2 :: \kappa_2 \qquad \Delta \vdash c_1
  :: \kappa_1
}{
  \Delta \vdash (\lambda(u :: \kappa_1). \, c_2)(c_1) \equiv  [c_1/u]c_2 :: \kappa_2
}
$$</p>

<p>We can think of this as saying &ldquo;when you apply one type to another, the
second type gets full access to the first type to construct a new type.&rdquo;
We notice that the substitution here is completely <strong>internal to the
type system</strong>.<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup></p>

<p>On the other hand, the substitution for <code>∀</code> <strong>bridges the gap</strong> from
types to terms:</p>

<p>$$
\frac{
  \Delta \, \Gamma, e : \forall (u :: \kappa). \tau \qquad \Delta \vdash c :: \kappa
}{
  \Delta \, \Gamma \vdash e[c] : [c/u]\tau
}
$$
$$
\frac{
  \mbox{}
}{
  (\Lambda u. \, e)[\tau] \mapsto [\tau / u]e
}
$$</p>

<p>When we&rsquo;re type checking a polymorphic type application, we don&rsquo;t get to
know anything about the type parameter <code>u</code> other than its kind. But when
we&rsquo;re running a program and get to the evaluation of a polymorphic type
application, we substitute the concrete <code>τ</code> directly in for <code>u</code> in <code>e</code>,
which bridges the gap from the type-level to the term-level.</p>

<p>At the end of the day, all the interesting stuff came from using
functions (aka, something parameterized by a value) in cool ways. Isn&rsquo;t
that baffling? Functions are so powerful that they seem to always pop up
at the heart of the most interesting constructs. I think it&rsquo;s
straight-up amazing that something so simple can at the same time be
that powerful. Functions!</p>

<!-- vim:tw=72
-->

<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>It&rsquo;s easy to not notice at first that type definitions are really function calls because in Standard ML, the type function applications are backwards. Instead of <code>f(x)</code>, it&rsquo;s <code>x f</code>. This is more similar to how we actually think when we see a function. Consider <code>h(g(f(x)))</code> (or another way: <code>h . g . f $ x</code>). We read this as &ldquo;take x, do f, pass that to g, and pass that to h&rdquo;. Why not write <code>x f g h</code> in the first place?<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>Other languages (like Haskell or PureScript) have a language feature called &ldquo;Rank-N Types&rdquo; which is really just a fancy way of saying &ldquo;you can put the <code>forall a.</code> anywhere you want.&rdquo; Oftentimes, this makes it harder for the compiler to infer where the variable bindings are, so you sometimes have to use more annotations than you might if you weren&rsquo;t using Rank-N types.<a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p>It&rsquo;s not super relevant to this discussion, but this inference rule is for the judgement defining equality of type constructors. This comes up all over the place when you&rsquo;re writing a compiler for SML. If this sounds interesting, definitely take 15-417 HOT Compilation!<a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SML Dev Setup]]></title>
    <link href="https://blog.jez.io/sml-dev-setup/"/>
    <updated>2016-03-09T21:06:15-05:00</updated>
    <id>https://blog.jez.io/sml-dev-setup</id>
    <content type="html"><![CDATA[<p>When it comes right down to it, SML is a pretty great language. It&rsquo;s clear that
extensive thought has gone into its design and implementation. I quite enjoy
programming in SML, due in no small part to my collection of workflow hacks that
make editing and developing with SML responsive and interactive.</p>

<!-- more -->


<p>We&rsquo;re going to be walking through a couple easy steps you can take to make
developing SML feel more fluid, both in and out of your editor. I have a slight
preference for Vim on OS X, but many of these steps are platform agnostic.</p>

<h2>Installing SML Locally</h2>

<p>While developing SML in a remote environment like the shared Andrew Unix
machines makes it easy to dive right in, working with SML for prolonged periods
of time is best done locally.</p>

<p>On OS X and Ubuntu, the two most popular SML implementations are already
packaged. Take the time to install a version of SML right now. At CMU, we use
<a href="http://smlnj.org/">SML/NJ</a>, which is convenient because it has a REPL that lets you play
around with SML interactively. If you&rsquo;d like to play around with compiling and
distributing programs written in SML, you might want to install <a href="http://www.mlton.org/">MLton</a>.</p>

<pre><code class="bash Install SML from your package manager"># SML/NJ on OS X
brew install smlnj
# -- or --
# MLton on OS X
brew install mlton

# SML/NJ on Ubuntu
sudo apt-get install smlnj
# -- or --
# MLton on Ubuntu
sudo apt-get install mlton
</code></pre>

<p>Feel free to install both if you&rsquo;d like; they&rsquo;ll play nicely with each other and
each offers advantages over the other.</p>

<p>Note for OS X users: if you&rsquo;ve never used <a href="http://brew.sh">Homebrew</a> before, you&rsquo;ll need
to <a href="http://brew.sh">install it first</a>.</p>

<h2>Getting Comfortable with SML/NJ</h2>

<p>The rest of these steps should apply regardless of whether you&rsquo;re working on SML
locally or remotely.</p>

<p>One thing that I&rsquo;ve seen far too many times from course documentation is that
they tell students to run their code like this:</p>

<ol>
<li>Run <code>sml</code></li>
<li>Type <code>use "foo.sml";</code> or <code>CM.make "sources.cm";</code> at the REPL</li>
</ol>


<p>Don&rsquo;t get me wrong; this works, but there&rsquo;s a better way. Being responsible
CLI-citizens, we should always be looking for ways to tab-complete. Let&rsquo;s do
this by changing our workflow:</p>

<ol>
<li>Run <code>sml foo.sml</code> or <code>sml -m sources.cm</code></li>
</ol>


<p>Look at that! We&rsquo;ve,</p>

<ul>
<li>dropped a step (having to launch the REPL first), and</li>
<li>introduced tab completion into our workflow (because the shell has filename
completion)</li>
</ul>


<p>It&rsquo;s the little things, but they add up.</p>

<h2>Enhancing the REPL</h2>

<p>Speaking of the little things, when using the SML REPL, you don&rsquo;t have access to
all the usual command line niceties like command history and access to arrow
keys for editing, let alone Vi-like keybindings. To get started, you&rsquo;ll have to
change how you launch the SML/NJ REPL. In particular, we&rsquo;re going to preface our
commands with <code>rlwrap</code>:</p>

<pre><code class="bash"># instead of this...
$ sml

# use this:
$ rlwrap sml
</code></pre>

<p><code>rlwrap</code> stands for &ldquo;readline wrap.&rdquo; Readline is a library that simply adds to a
REPL program all the features mentioned above:</p>

<ul>
<li>Command history tracking</li>
<li>Line editing with arrow keys</li>
<li>Configurability through the <code>~/.inputrc</code> file

<ul>
<li>We can use this to get fancy features like Vi keybindings</li>
</ul>
</li>
</ul>


<p>For more information, see <a href="https://github.com/jez/dotfiles/blob/ed8e531eebe43a8aef05fc4cb768157d03408cea/inputrc#L12-L14">these lines</a> of my inputrc, a small part of
my <a href="https://github.com/jez/dotfiles">dotfiles repo</a> on GitHub.</p>

<h2>Setting Up Vim</h2>

<p>Programming is so much more enjoyable when you&rsquo;re not fighting your editor. For
me, this means striving to get the most out of Vim. In this section, I&rsquo;ll
outline all the cool tips and tricks I have for developing SML in Vim.</p>

<p>But first, if you&rsquo;ve never taken a look into how to configure Vim, I suggest you
start out by walking through this quick workshop called <a href="https://github.com/jez/vim-as-an-ide">Vim as an
IDE</a>. It&rsquo;ll teach you where to start when configuring Vim and get
you set up with a bunch of standard plugins that improve on the standard Vim
experience tenfold.</p>

<p>No actually, take a second and <a href="https://github.com/jez/vim-as-an-ide">walk through it</a>. We&rsquo;ll still be
here when you&rsquo;re done, and you&rsquo;ll appreciate Vim more when you&rsquo;re done.</p>

<h3>Syntastic</h3>

<p>From the Syntastic documentation:</p>

<blockquote><p>Syntastic is a syntax checking plugin for Vim that runs files through
external syntax checkers and displays any resulting errors to the user. This
can be done on demand, or automatically as files are saved. If syntax errors
are detected, the user is notified and is happy because they didn&rsquo;t have to
compile their code or execute their script to find them.</p></blockquote>

<p>And the best part? Syntastic ships with a checker for SML by default if you
have SML/NJ installed.</p>

<p>If you didn&rsquo;t just install <a href="https://github.com/scrooloose/syntastic">Syntastic</a> from the Vim as an IDE
walkthrough, you can <a href="https://github.com/scrooloose/syntastic">visit their homepage</a> for installation
instructions. Go ahead and do this now, then try writing this in a file called
<code>test.sml</code>:</p>

<pre><code class="sml test.sml">val foo : string = 42
</code></pre>

<p>You should see an &lsquo;x&rsquo; next to the line and a description of the error from the
type checker. You can imagine how handy this is.</p>

<h3>Extra Syntastic Setup</h3>

<p>Syntastic has their own set of <a href="https://github.com/scrooloose/syntastic#settings">recommended settings</a> that
you can add at your discretion. At the very least, I&rsquo;d suggest adding these
lines to your vimrc:</p>

<pre><code class="vim .vimrc">...

augroup mySyntastic
  " tell syntastic to always stick any detected errors into the location-list
  au FileType sml let g:syntastic_always_populate_loc_list = 1

  " automatically open and/or close the location-list
  au FileType sml let g:syntastic_auto_loc_list = 1
augroup END

" press &lt;Leader&gt;S (i.e., \S) to not automatically check for errors
nnoremap &lt;Leader&gt;S :SyntasticToggleMode&lt;CR&gt;

...
</code></pre>

<p>By default, whenever you save your file, Syntastic will place symbols in Vim&rsquo;s
<em>sign column</em> next to lines with errors. The first two settings above tell
Syntastic to also show a summarized list of errors at the bottom of the screen.
The final setting lets you press <code>&lt;Leader&gt;S</code> (which is usually just <code>\S</code>) to
disable all that. This is useful when you&rsquo;re still unfinished and you know your
SML isn&rsquo;t going to type check. Press it again to re-enable it.</p>

<p>Also, a tip for those who&rsquo;ve never used Vim&rsquo;s location list feature before: you
can close the list with <code>:lclose</code>.</p>

<h3><code>vim-better-sml</code></h3>

<p>The curious at this point might be wondering if Syntastic is smart enough to
figure out when the file you&rsquo;re using requires a CM file to compile and uses it
to show you where the errors are instead. As it turns out: no, <a href="https://github.com/scrooloose/syntastic/pull/1719">that&rsquo;s not a
feature Syntastic wants to include</a> by default. However, the
functionality isn&rsquo;t hard to implement, and there&rsquo;s already a plugin for it!</p>

<p><a href="https://github.com/jez/vim-better-sml">vim-better-sml</a> is one of my Vim plugins. Here&rsquo;s a quick
rundown of its features:</p>

<ul>
<li>As already mentioned, it will detect when your file requires a CM file to
build, and will pass along the information to Syntastic</li>
<li><code>let</code> expressions are indented one level under <code>fun</code> declarations</li>
<li><code>*.sig</code> files are properly detected as SML signature files</li>
<li>Apostrophe characters are treated as keywords characters</li>
<li>The comment string is properly registered for SML files</li>
</ul>


<p>For more information, including how to install it, check out the homepage:
<a href="https://github.com/jez/vim-better-sml">vim-better-sml</a>.</p>

<h2>General Vim Settings</h2>

<p>As a quick addendum, one common complaint people have when editing SML is that
it forces the line to wrap if it extends to 80 characters. Some people don&rsquo;t
like that it does this, and others don&rsquo;t like that it doesn&rsquo;t do it frequently
enough (namely, it only wraps the line if your cursor extends past 80
characters, not the end of the line).</p>

<p>If you don&rsquo;t want Vim to do any of this wrapping, run this:</p>

<pre><code class="vim Disable hard line wrapping">setlocal textwidth=0
</code></pre>

<p>If you&rsquo;d like this change to persist between Vim sessions, add it to
<code>~/.vim/after/ftplugin/sml.vim</code>. These folders and file likely don&rsquo;t exist
yet; you&rsquo;ll have to create them. The <code>after</code> folder in Vim is used to override
settings loaded from plugins. As you might have guessed, files in here are run
after plugin code is.</p>

<p>Conversely, if you&rsquo;d like a little better idea when Vim&rsquo;s going to hard wrap
your line, you can add this line to your vimrc:</p>

<pre><code class="vim Show a color column">set colorcolumn+=0
</code></pre>

<p>Note: this will only work if you&rsquo;re using Vim 7.4 or above. This setting tells
Vim to draw a solid column at the same width as the value of the <code>textwidth</code>
setting.</p>

<h2>TL;DR</h2>

<p>We covered a lot, so here&rsquo;s a quick recap:</p>

<ul>
<li>Install SML locally. It&rsquo;s super easy to do on OS X and Linux (use your package
manager), and means you don&rsquo;t have have a Wi-Fi connection to develop SML.</li>
<li>Invest time into learning Vim. Here&rsquo;s a reference: <a href="https://github.com/jez/vim-as-an-ide">Vim as an
IDE</a>.</li>
<li>Install <a href="https://github.com/scrooloose/syntastic">Syntastic</a>. It tells you what lines your errors are on.</li>
<li>Install <a href="https://github.com/jez/vim-better-sml">vim-better-sml</a>. It includes some features Syntastic
doesn&rsquo;t by default, and includes a couple extras.</li>
<li>Consider using <code>setlocal textwidth=0</code> or <code>set colorcolumn+=0</code> to deal with the
80-character restriction when writing SML files.</li>
</ul>


<p>And as always, you can see even more Vim settings in my <a href="https://github.com/jez/dotfiles">dotfiles
repo</a> on GitHub.</p>
]]></content>
  </entry>
  
</feed>
